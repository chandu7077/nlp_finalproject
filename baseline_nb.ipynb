{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "## Game of Thrones Text Classification\n",
    "### T. P. Goter\n",
    "### W266 Final Project\n",
    "### Fall 2019\n",
    "\n",
    "This notebook is used to generate a Naive Bayes model for text classification using training data generated for the Game of Thrones novel. A simple GridSearch with cross validation is done for each model in order to empirically determine the best parameter of for smoothing (i.e., alpha). Both unigram and bigram models are considered. Additionally, consideration is given to a tfidf vectorication vice a simple word count vectorization. The results of these studies show that all four models perform about the same and have precision, recall and f1 scores near 0.70. Class 5 (i.e., Book 5) shows as the most easily predicted. This isn't really surprising given books four and five were focused on a subset of the characters. Thus, word counts of character names likely are better indicators for these books. With 70% accuracy as our baseline score on the development set, there is plenty of room for further improvement with BERT and the UDA techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# import the tokenization module\n",
    "from utils import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into dataframes stored in a dictionary\n",
    "dfs = {}\n",
    "for data in 'train dev test'.split():\n",
    "    dfs[data] = pd.read_pickle('Data/' + data + '/' + data + '.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_model(df_train, df_dev, train_size=None, bigram=False, tfidf=False, tokenize=False):\n",
    "    '''\n",
    "    Function to train and evalute a multinomial naive bayes model.\n",
    "    :param: bigram: Boolean, use unigram and bigrams\n",
    "    :param: tfidf: Boolean, use tfidf weighting during feature vectorization\n",
    "    :param: tokenize: Boolean, use WordPiece tokenization with BERT input vocabulary\n",
    "    '''\n",
    "    # Set up a range of alphas to test\n",
    "    alphas = {'alpha': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "     \n",
    "    # Get data and labels from dataframe\n",
    "    if tokenize: \n",
    "        if train_size:\n",
    "            reduced_df = reduced_df.sample(train_size)\n",
    "            train_data = df_train.tokens.map(lambda x: \" \".join(x))\n",
    "            train_y = reduced_df.label\n",
    "        else:      \n",
    "            train_data = df_train.tokens.map(lambda x: \" \".join(x))\n",
    "            train_y = df_train.label\n",
    "        dev_data = df_dev.tokens.map(lambda x: \" \".join(x))\n",
    "    else:\n",
    "        if train_size:\n",
    "            reduced_df = df_train.sample(train_size)\n",
    "            train_data = reduced_df.text\n",
    "            train_y = reduced_df.label\n",
    "        else:\n",
    "            train_data = df_train.text\n",
    "            train_y = df_train.label\n",
    "        dev_data = df_dev.text\n",
    "    \n",
    "    \n",
    "    dev_y = df_dev.label\n",
    "    \n",
    "    # Instantiate the count vectorizer\n",
    "    if bigram:\n",
    "        if tfidf:\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "        else:\n",
    "            vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "    else:\n",
    "        if tfidf:\n",
    "            vectorizer = TfidfVectorizer()\n",
    "        else:\n",
    "            vectorizer = CountVectorizer()\n",
    "    \n",
    "    # Generate the Feature Vectors\n",
    "    train_X = vectorizer.fit_transform(train_data)    \n",
    "    \n",
    "    # Generate the vocabulary for the dev data\n",
    "    dev_X = vectorizer.transform(dev_data)\n",
    "       \n",
    "    # Fit the model\n",
    "    clf = MultinomialNB()\n",
    "    \n",
    "    # Run a grid search over alpha (smoothing) values to determine best \n",
    "    gs_clf = GridSearchCV(clf, param_grid=alphas, cv=4, return_train_score=True)\n",
    "    gs_clf.fit(train_X, train_y)\n",
    "    \n",
    "    # Display the best parameter\n",
    "    print(50 * \"=\")\n",
    "    print(\"The best alpha value was determined to be {}\".format(gs_clf.best_params_['alpha']))\n",
    "    print(50 * \"=\")\n",
    "\n",
    "    # Let's make some predictions using the best classifier\n",
    "    y_pred = gs_clf.best_estimator_.predict(dev_X)\n",
    "       \n",
    "    print(classification_report(y_pred, dev_y))\n",
    "    print(confusion_matrix(dev_y, y_pred))\n",
    "    \n",
    "    return gs_clf.best_estimator_.feature_log_prob_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Unigram Model\n",
    "\n",
    "Metrics we will consider are precision, recall, and F1-score. Remember that:\n",
    "\n",
    "- Precision: Number of items labeled as class A that are actually class A. - How many false positives?\n",
    "- Recall: Number of items labeled as class A normalized to all things that are class A. - How many false negatives?\n",
    "- F1 Score: Harmonic mean of Precision and Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 0.5\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.70      0.74       481\n",
      "           2       0.58      0.70      0.63       407\n",
      "           3       0.63      0.65      0.64       577\n",
      "           4       0.76      0.70      0.73       446\n",
      "           5       0.78      0.77      0.77       590\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      2501\n",
      "   macro avg       0.71      0.70      0.70      2501\n",
      "weighted avg       0.71      0.70      0.71      2501\n",
      "\n",
      "[[335  34  39   7   9]\n",
      " [ 75 284  70  26  34]\n",
      " [ 48  66 375  46  57]\n",
      " [  8  14  40 314  35]\n",
      " [ 15   9  53  53 455]]\n"
     ]
    }
   ],
   "source": [
    "uni_probs = create_basic_model(dfs['train'], dfs['dev'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 0.1\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.73      0.74       432\n",
      "           2       0.54      0.69      0.61       384\n",
      "           3       0.72      0.65      0.68       660\n",
      "           4       0.74      0.75      0.74       409\n",
      "           5       0.80      0.76      0.78       616\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      2501\n",
      "   macro avg       0.71      0.71      0.71      2501\n",
      "weighted avg       0.72      0.71      0.71      2501\n",
      "\n",
      "[[315  45  43   4  17]\n",
      " [ 65 265  97  26  36]\n",
      " [ 33  50 426  28  55]\n",
      " [  9  13  42 305  42]\n",
      " [ 10  11  52  46 466]]\n"
     ]
    }
   ],
   "source": [
    "bi_probs = create_basic_model(dfs['train'], dfs['dev'], bigram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram Model with Tf-Idf Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 0.1\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.76      0.74       394\n",
      "           2       0.50      0.71      0.59       347\n",
      "           3       0.74      0.58      0.65       756\n",
      "           4       0.68      0.77      0.72       363\n",
      "           5       0.81      0.74      0.77       641\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      2501\n",
      "   macro avg       0.69      0.71      0.69      2501\n",
      "weighted avg       0.71      0.69      0.70      2501\n",
      "\n",
      "[[301  33  70   4  16]\n",
      " [ 54 245 122  23  45]\n",
      " [ 24  46 440  24  58]\n",
      " [  6  13  62 280  50]\n",
      " [  9  10  62  32 472]]\n"
     ]
    }
   ],
   "source": [
    "uni_tfidf_probs = create_basic_model(dfs['train'], dfs['dev'], tfidf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Model with Tf-Idf Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 0.01\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.74      0.72       396\n",
      "           2       0.50      0.67      0.58       365\n",
      "           3       0.74      0.61      0.67       715\n",
      "           4       0.70      0.77      0.73       373\n",
      "           5       0.79      0.71      0.75       652\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      2501\n",
      "   macro avg       0.69      0.70      0.69      2501\n",
      "weighted avg       0.71      0.69      0.69      2501\n",
      "\n",
      "[[294  48  53   3  26]\n",
      " [ 59 246 117  20  47]\n",
      " [ 25  45 438  22  62]\n",
      " [ 10  15  47 286  53]\n",
      " [  8  11  60  42 464]]\n"
     ]
    }
   ],
   "source": [
    "bi_tfidf_probs = create_basic_model(dfs['train'], dfs['dev'], tfidf=True, bigram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Dataset to 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 0.5\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.70      0.74       478\n",
      "           2       0.57      0.69      0.62       403\n",
      "           3       0.66      0.65      0.65       599\n",
      "           4       0.76      0.72      0.74       435\n",
      "           5       0.77      0.77      0.77       586\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      2501\n",
      "   macro avg       0.71      0.71      0.71      2501\n",
      "weighted avg       0.71      0.71      0.71      2501\n",
      "\n",
      "[[335  31  39   8  11]\n",
      " [ 78 277  73  22  39]\n",
      " [ 42  67 389  43  51]\n",
      " [  8  16  39 314  34]\n",
      " [ 15  12  59  48 451]]\n"
     ]
    }
   ],
   "source": [
    "uni_probs = create_basic_model(dfs['train'], dfs['dev'], train_size=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 0.5\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.68      0.70       449\n",
      "           2       0.49      0.66      0.56       362\n",
      "           3       0.66      0.60      0.63       647\n",
      "           4       0.69      0.68      0.68       414\n",
      "           5       0.76      0.71      0.73       629\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      2501\n",
      "   macro avg       0.66      0.67      0.66      2501\n",
      "weighted avg       0.68      0.66      0.67      2501\n",
      "\n",
      "[[306  32  52  10  24]\n",
      " [ 67 240 103  28  51]\n",
      " [ 42  48 390  48  64]\n",
      " [ 17  17  50 282  45]\n",
      " [ 17  25  52  46 445]]\n"
     ]
    }
   ],
   "source": [
    "uni_probs = create_basic_model(dfs['train'], dfs['dev'], train_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 0.5\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.68      0.62       353\n",
      "           2       0.42      0.49      0.45       418\n",
      "           3       0.64      0.51      0.56       747\n",
      "           4       0.58      0.61      0.59       390\n",
      "           5       0.65      0.64      0.65       593\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2501\n",
      "   macro avg       0.57      0.58      0.57      2501\n",
      "weighted avg       0.58      0.58      0.58      2501\n",
      "\n",
      "[[239  69  70  16  30]\n",
      " [ 54 206 130  36  63]\n",
      " [ 32  69 378  45  68]\n",
      " [ 11  36  75 237  52]\n",
      " [ 17  38  94  56 380]]\n"
     ]
    }
   ],
   "source": [
    "uni_probs = create_basic_model(dfs['train'], dfs['dev'], train_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 0.1\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.38      0.39       465\n",
      "           2       0.33      0.29      0.31       557\n",
      "           3       0.29      0.37      0.32       464\n",
      "           4       0.36      0.40      0.38       372\n",
      "           5       0.49      0.44      0.46       643\n",
      "\n",
      "   micro avg       0.38      0.38      0.38      2501\n",
      "   macro avg       0.38      0.38      0.37      2501\n",
      "weighted avg       0.38      0.38      0.38      2501\n",
      "\n",
      "[[175  88  66  32  63]\n",
      " [ 99 162  89  35 104]\n",
      " [ 96 128 171  80 117]\n",
      " [ 37  90  59 150  75]\n",
      " [ 58  89  79  75 284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "uni_probs = create_basic_model(dfs['train'], dfs['dev'], train_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 1.0\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.01      0.18      0.01        17\n",
      "           2       0.91      0.20      0.32      2272\n",
      "           3       0.06      0.26      0.10       145\n",
      "           4       0.03      0.36      0.06        39\n",
      "           5       0.01      0.18      0.02        28\n",
      "\n",
      "   micro avg       0.20      0.20      0.20      2501\n",
      "   macro avg       0.20      0.23      0.10      2501\n",
      "weighted avg       0.83      0.20      0.30      2501\n",
      "\n",
      "[[  3 383  22  10   6]\n",
      " [  3 446  27   5   8]\n",
      " [  6 538  37   7   4]\n",
      " [  2 356  34  14   5]\n",
      " [  3 549  25   3   5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "uni_probs = create_basic_model(dfs['train'], dfs['dev'], train_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Consistent Training Data with UDA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_bert_model(df_train, df_dev, bigram=False, tfidf=False):\n",
    "    '''\n",
    "    Function to train and evalute a multinomial naive bayes model.\n",
    "    :param: bigram: Boolean, use unigram and bigrams\n",
    "    :param: tfidf: Boolean, use tfidf weighting during feature vectorization\n",
    "    :param: tokenize: Boolean, use WordPiece tokenization with BERT input vocabulary\n",
    "    '''\n",
    "    # Set up a range of alphas to test\n",
    "    alphas = {'alpha': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "     \n",
    "    # Get data and labels from dataframe\n",
    "    train_data = df_train.seq\n",
    "    train_y = df_train.label.map(lambda x: str(x))\n",
    "\n",
    "    dev_data = df_dev.tokens.map(lambda x: \" \".join(x))\n",
    "    dev_y = df_dev.label\n",
    "    \n",
    "    # Instantiate the count vectorizer\n",
    "    if bigram:\n",
    "        if tfidf:\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "        else:\n",
    "            vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "    else:\n",
    "        if tfidf:\n",
    "            vectorizer = TfidfVectorizer()\n",
    "        else:\n",
    "            vectorizer = CountVectorizer()\n",
    "    \n",
    "    # Generate the Feature Vectors\n",
    "    train_X = vectorizer.fit_transform(train_data)    \n",
    "    \n",
    "    # Generate the vocabulary for the dev data\n",
    "    dev_X = vectorizer.transform(dev_data)\n",
    "       \n",
    "    # Fit the model\n",
    "    clf = MultinomialNB()\n",
    "    \n",
    "    # Run a grid search over alpha (smoothing) values to determine best \n",
    "    gs_clf = GridSearchCV(clf, param_grid=alphas, cv=4, return_train_score=True)\n",
    "    gs_clf.fit(train_X, train_y)\n",
    "    \n",
    "    # Display the best parameter\n",
    "    print(50 * \"=\")\n",
    "    print(\"The best alpha value was determined to be {}\".format(gs_clf.best_params_['alpha']))\n",
    "    print(50 * \"=\")\n",
    "\n",
    "    # Let's make some predictions using the best classifier\n",
    "    y_pred = gs_clf.best_estimator_.predict(dev_X)\n",
    "       \n",
    "    print(classification_report(dev_y,y_pred))\n",
    "    print(confusion_matrix(dev_y, y_pred))\n",
    "    print(\"Accuracy determined to be: {:.3f}\".format(np.mean(y_pred==dev_y)))\n",
    "    \n",
    "    return gs_clf.best_estimator_.feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] you ’ ve been hurt . he took her hands i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] pinch ##bot ##tom pet ##to and sl ##oe -...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] is it his fault the old man died ? stan ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] the battle ##ments br ##istle ##d with s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] for all his ru ##tting , he has not prov...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[CLS] he called his servants and sent them run...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[CLS] they have no trees , she realized . bra ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[CLS] lord wal ##der might well con ##st ##ru ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[CLS] still fighting on the fist , amidst heav...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[CLS] twenty mule ##s awaited them within the ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[CLS] he has no bride to gr ##ie ##ve for him ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[CLS] then rage replaced it . ce ##rse ##i gat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[CLS] theo ##n ’ s anger flared . he ’ d led m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[CLS] sweet ce ##rse ##i , always st ##ri ##vi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[CLS] one , two , three , four , da ##vos coun...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[CLS] dan ##y remembered the story vis ##ery #...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[CLS] islander . a third of bala ##q ’ s men u...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[CLS] gen ##dry ’ s mare lost her footing in t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[CLS] dragons and open the gates to the queen ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[CLS] she would have been my daughter , if the...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  seq  label\n",
       "0   [CLS] you ’ ve been hurt . he took her hands i...      1\n",
       "1   [CLS] pinch ##bot ##tom pet ##to and sl ##oe -...      2\n",
       "2   [CLS] is it his fault the old man died ? stan ...      2\n",
       "3   [CLS] the battle ##ments br ##istle ##d with s...      1\n",
       "4   [CLS] for all his ru ##tting , he has not prov...      5\n",
       "5   [CLS] he called his servants and sent them run...      1\n",
       "6   [CLS] they have no trees , she realized . bra ...      4\n",
       "7   [CLS] lord wal ##der might well con ##st ##ru ...      3\n",
       "8   [CLS] still fighting on the fist , amidst heav...      3\n",
       "9   [CLS] twenty mule ##s awaited them within the ...      4\n",
       "10  [CLS] he has no bride to gr ##ie ##ve for him ...      4\n",
       "11  [CLS] then rage replaced it . ce ##rse ##i gat...      3\n",
       "12  [CLS] theo ##n ’ s anger flared . he ’ d led m...      2\n",
       "13  [CLS] sweet ce ##rse ##i , always st ##ri ##vi...      2\n",
       "14  [CLS] one , two , three , four , da ##vos coun...      5\n",
       "15  [CLS] dan ##y remembered the story vis ##ery #...      1\n",
       "16  [CLS] islander . a third of bala ##q ’ s men u...      5\n",
       "17  [CLS] gen ##dry ’ s mare lost her footing in t...      3\n",
       "18  [CLS] dragons and open the gates to the queen ...      5\n",
       "19  [CLS] she would have been my daughter , if the...      4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20 = pd.read_pickle('Data/proc_data/GoT/train_20/train_20.pkl')\n",
    "df_20.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 1.0\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.25      0.29       424\n",
      "           2       0.22      0.35      0.27       489\n",
      "           3       0.26      0.31      0.28       592\n",
      "           4       0.20      0.13      0.16       411\n",
      "           5       0.33      0.24      0.28       585\n",
      "\n",
      "   micro avg       0.26      0.26      0.26      2501\n",
      "   macro avg       0.27      0.26      0.26      2501\n",
      "weighted avg       0.27      0.26      0.26      2501\n",
      "\n",
      "[[105 116 113  40  50]\n",
      " [ 50 173 141  48  77]\n",
      " [ 64 169 184  65 110]\n",
      " [ 32 128 142  55  54]\n",
      " [ 47 197 129  70 142]]\n",
      "Accuracy determined to be: 0.263\n"
     ]
    }
   ],
   "source": [
    "uni_probs = create_basic_bert_model(df_20, dfs['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 0.1\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.44      0.41       424\n",
      "           2       0.30      0.35      0.32       489\n",
      "           3       0.37      0.30      0.33       592\n",
      "           4       0.44      0.35      0.39       411\n",
      "           5       0.47      0.51      0.49       585\n",
      "\n",
      "   micro avg       0.39      0.39      0.39      2501\n",
      "   macro avg       0.39      0.39      0.39      2501\n",
      "weighted avg       0.39      0.39      0.39      2501\n",
      "\n",
      "[[187  97  60  19  61]\n",
      " [ 92 171 116  27  83]\n",
      " [108 116 177  68 123]\n",
      " [ 42  95  60 145  69]\n",
      " [ 54  95  66  71 299]]\n",
      "Accuracy determined to be: 0.391\n"
     ]
    }
   ],
   "source": [
    "df_200 = pd.read_pickle('Data/proc_data/GoT/train_200/train_200.pkl')\n",
    "uni_probs_200 = create_basic_bert_model(df_200, dfs['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 2.0\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.75      0.63       424\n",
      "           2       0.55      0.34      0.42       489\n",
      "           3       0.51      0.52      0.51       592\n",
      "           4       0.56      0.66      0.60       411\n",
      "           5       0.68      0.61      0.64       585\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      2501\n",
      "   macro avg       0.57      0.58      0.56      2501\n",
      "weighted avg       0.57      0.57      0.56      2501\n",
      "\n",
      "[[320  31  51  10  12]\n",
      " [118 167 117  42  45]\n",
      " [ 85  54 308  80  65]\n",
      " [ 18  23  55 270  45]\n",
      " [ 47  28  74  80 356]]\n",
      "Accuracy determined to be: 0.568\n"
     ]
    }
   ],
   "source": [
    "df_2000 = pd.read_pickle('Data/proc_data/GoT/train_2000/train_2000.pkl')\n",
    "uni_probs_2000 = create_basic_bert_model(df_2000, dfs['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 1.0\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.75      0.69       424\n",
      "           2       0.60      0.45      0.51       489\n",
      "           3       0.55      0.63      0.58       592\n",
      "           4       0.64      0.69      0.67       411\n",
      "           5       0.75      0.65      0.69       585\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      2501\n",
      "   macro avg       0.63      0.63      0.63      2501\n",
      "weighted avg       0.63      0.63      0.63      2501\n",
      "\n",
      "[[318  39  48   7  12]\n",
      " [ 83 219 119  33  35]\n",
      " [ 58  62 372  48  52]\n",
      " [ 14  15  66 285  31]\n",
      " [ 25  32  76  72 380]]\n",
      "Accuracy determined to be: 0.629\n"
     ]
    }
   ],
   "source": [
    "df_5000 = pd.read_pickle('Data/proc_data/GoT/train_5000/train_5000.pkl')\n",
    "uni_probs_5000 = create_basic_bert_model(df_5000, dfs['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "The best alpha value was determined to be 1.0\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.75      0.71       424\n",
      "           2       0.63      0.49      0.55       489\n",
      "           3       0.58      0.67      0.62       592\n",
      "           4       0.67      0.73      0.70       411\n",
      "           5       0.78      0.68      0.73       585\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      2501\n",
      "   macro avg       0.67      0.67      0.66      2501\n",
      "weighted avg       0.67      0.66      0.66      2501\n",
      "\n",
      "[[316  40  43  11  14]\n",
      " [ 75 242 108  36  28]\n",
      " [ 42  66 395  44  45]\n",
      " [ 11  14  55 302  29]\n",
      " [ 20  22  84  59 400]]\n",
      "Accuracy determined to be: 0.662\n"
     ]
    }
   ],
   "source": [
    "df_12000 = pd.read_pickle('Data/proc_data/GoT/train_12000/train_12000.pkl')\n",
    "uni_probs_12000 = create_basic_bert_model(df_12000, dfs['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
