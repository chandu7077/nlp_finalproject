{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "import pandas as pd\n",
    "from utils import tokenization\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data and Tokenize\n",
    "We use the basic tokenizer (prior to the wordpiece tokenization) for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data fround in a previously generated pickle file (dataframe)\n",
    "train_data = 'Data/train/train.pkl'\n",
    "\n",
    "# Using the Basic Tokenizer which just separates into words and punctuation (not wordpieces)\n",
    "tokenizer = tokenization.BasicTokenizer()\n",
    "\n",
    "train_df = pd.read_pickle(train_data)\n",
    "words_df = pd.DataFrame()\n",
    "\n",
    "# Each row of dataframe will have a column containing a list of the tokenized sequence\n",
    "words_df['words'] = train_df.text.map(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>[he, snatched, it, one, -, handed, from, the, ...</td>\n",
       "      <td>[3, 1, 2, 1, 1, 1, 2, 8, 1, 3, 1, 2, 1, 3, 2, ...</td>\n",
       "      <td>[1.3998152, 6.4415517, 1.609062, 2.3551874, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8155</th>\n",
       "      <td>[some, believe, baelor, was, deranged, by, all...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 1, 5, 1, 1, 1, ...</td>\n",
       "      <td>[3.081176, 4.8825974, 6.020819, 1.4650301, 9.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685</th>\n",
       "      <td>[come, ., ., ., closer, ., his, men, brought, ...</td>\n",
       "      <td>[1, 17, 17, 17, 1, 17, 4, 1, 1, 1, 1, 17, 1, 1...</td>\n",
       "      <td>[3.2699287, 1.0, 1.0, 1.0, 5.401003, 1.0, 1.46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>[she, spun, away, and, said, to, him, ,, no, f...</td>\n",
       "      <td>[2, 1, 1, 7, 2, 1, 1, 10, 2, 1, 1, 2, 5, 2, 1,...</td>\n",
       "      <td>[1.963341, 6.1273026, 3.496303, 1.093492, 2.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>[poisons, and, potions, were, for, the, aftern...</td>\n",
       "      <td>[2, 8, 1, 1, 3, 4, 1, 5, 4, 2, 2, 8, 2, 8, 2, ...</td>\n",
       "      <td>[8.536497, 1.093492, 7.5714164, 2.2945173, 1.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13483</th>\n",
       "      <td>[no, ,, cressen, thought, ., nor, will, they, ...</td>\n",
       "      <td>[2, 7, 1, 1, 15, 1, 1, 2, 1, 15, 1, 2, 1, 7, 1...</td>\n",
       "      <td>[2.1970203, 1.0010004, 6.472804, 3.1298862, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8542</th>\n",
       "      <td>[weasel, ,, weese, purred, ,, next, time, i, s...</td>\n",
       "      <td>[1, 7, 1, 1, 7, 1, 1, 2, 2, 1, 1, 1, 1, 7, 2, ...</td>\n",
       "      <td>[6.8547387, 1.0010004, 6.9023666, 8.536497, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10869</th>\n",
       "      <td>[the, smoke, was, stinging, his, eyes, ., tyri...</td>\n",
       "      <td>[5, 1, 2, 1, 3, 1, 6, 1, 1, 3, 1, 3, 1, 1, 1, ...</td>\n",
       "      <td>[1.014097, 5.4064527, 1.4650301, 7.725567, 1.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12295</th>\n",
       "      <td>[robb, and, bran, and, rickon, ., they, ’, re,...</td>\n",
       "      <td>[1, 2, 1, 2, 1, 11, 1, 4, 1, 1, 11, 5, 2, 2, 1...</td>\n",
       "      <td>[4.0967917, 1.093492, 4.050674, 1.093492, 5.87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>[you, never, killed, a, woman, before, ,, did,...</td>\n",
       "      <td>[5, 2, 1, 3, 1, 1, 8, 1, 5, 2, 1, 2, 1, 1, 1, ...</td>\n",
       "      <td>[1.7426108, 3.1181772, 4.573306, 1.1875076, 3....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   words  \\\n",
       "3616   [he, snatched, it, one, -, handed, from, the, ...   \n",
       "8155   [some, believe, baelor, was, deranged, by, all...   \n",
       "4685   [come, ., ., ., closer, ., his, men, brought, ...   \n",
       "2857   [she, spun, away, and, said, to, him, ,, no, f...   \n",
       "7971   [poisons, and, potions, were, for, the, aftern...   \n",
       "13483  [no, ,, cressen, thought, ., nor, will, they, ...   \n",
       "8542   [weasel, ,, weese, purred, ,, next, time, i, s...   \n",
       "10869  [the, smoke, was, stinging, his, eyes, ., tyri...   \n",
       "12295  [robb, and, bran, and, rickon, ., they, ’, re,...   \n",
       "4991   [you, never, killed, a, woman, before, ,, did,...   \n",
       "\n",
       "                                                      tf  \\\n",
       "3616   [3, 1, 2, 1, 1, 1, 2, 8, 1, 3, 1, 2, 1, 3, 2, ...   \n",
       "8155   [1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 1, 5, 1, 1, 1, ...   \n",
       "4685   [1, 17, 17, 17, 1, 17, 4, 1, 1, 1, 1, 17, 1, 1...   \n",
       "2857   [2, 1, 1, 7, 2, 1, 1, 10, 2, 1, 1, 2, 5, 2, 1,...   \n",
       "7971   [2, 8, 1, 1, 3, 4, 1, 5, 4, 2, 2, 8, 2, 8, 2, ...   \n",
       "13483  [2, 7, 1, 1, 15, 1, 1, 2, 1, 15, 1, 2, 1, 7, 1...   \n",
       "8542   [1, 7, 1, 1, 7, 1, 1, 2, 2, 1, 1, 1, 1, 7, 2, ...   \n",
       "10869  [5, 1, 2, 1, 3, 1, 6, 1, 1, 3, 1, 3, 1, 1, 1, ...   \n",
       "12295  [1, 2, 1, 2, 1, 11, 1, 4, 1, 1, 11, 5, 2, 2, 1...   \n",
       "4991   [5, 2, 1, 3, 1, 1, 8, 1, 5, 2, 1, 2, 1, 1, 1, ...   \n",
       "\n",
       "                                                     idf  \n",
       "3616   [1.3998152, 6.4415517, 1.609062, 2.3551874, 2....  \n",
       "8155   [3.081176, 4.8825974, 6.020819, 1.4650301, 9.9...  \n",
       "4685   [3.2699287, 1.0, 1.0, 1.0, 5.401003, 1.0, 1.46...  \n",
       "2857   [1.963341, 6.1273026, 3.496303, 1.093492, 2.07...  \n",
       "7971   [8.536497, 1.093492, 7.5714164, 2.2945173, 1.8...  \n",
       "13483  [2.1970203, 1.0010004, 6.472804, 3.1298862, 1....  \n",
       "8542   [6.8547387, 1.0010004, 6.9023666, 8.536497, 1....  \n",
       "10869  [1.014097, 5.4064527, 1.4650301, 7.725567, 1.4...  \n",
       "12295  [4.0967917, 1.093492, 4.050674, 1.093492, 5.87...  \n",
       "4991   [1.7426108, 3.1181772, 4.573306, 1.1875076, 3....  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Function for Generating Word Counts\n",
    "These are term frequencies - counts of each word per sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which will be used to generate a list of counts by word for each sequence\n",
    "def term_freq(seq):\n",
    "    counts = Counter(seq)\n",
    "    tf = []\n",
    "    for word in seq:\n",
    "        tf.append(counts[word])\n",
    "    return np.array(tf,dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a TF-IDF Vectorizer\n",
    "We want the inverse document frequencies for each word in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf vectorizer from sklearn with the Basic tokenizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenizer.tokenize)\n",
    "vectorizer.fit_transform(train_df.text)\n",
    "\n",
    "# Create a dictionary of words to idf values\n",
    "idf_by_feature = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that will be used to add IDFs for each word in each sequence of our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(seq):\n",
    "    idfs = []\n",
    "    for word in seq:\n",
    "        idfs.append(idf_by_feature[word])\n",
    "    return np.array(idfs,dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add tf and idf to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df['tf'] = words_df.words.map(lambda x: term_freq(x))\n",
    "words_df['idf'] = words_df.words.map(lambda x: idf(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Word Sampling and Word Replacement PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of word sampling probabilities: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Generate a sequence that is the entire training corpus\n",
    "word_list = []\n",
    "for seq in words_df.words:\n",
    "    word_list += seq\n",
    "    \n",
    "# Generate a count for each word\n",
    "wf_by_feature = Counter(word_list)\n",
    "\n",
    "# Calculate word scores by multiply word frequency by idf\n",
    "word_scores = {key:value*idf_by_feature[key] for key, value in wf_by_feature.items()}    \n",
    "\n",
    "# Max score\n",
    "max_score = max(word_scores.values())\n",
    "\n",
    "# Z-prime is how we will normalize our scores into a pdf (i.e., word probs need to sum to 1)\n",
    "z_prime = np.sum(max_score - np.array(list(word_scores.values())))\n",
    "\n",
    "word_probs = {key:(max_score-value)/z_prime for key, value in word_scores.items()}     \n",
    "\n",
    "# Check our math\n",
    "print(\"Sum of word sampling probabilities: {:5.4f}\".format(sum(word_probs.values())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_probs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>daughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>played</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cruel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>madness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>led</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aerys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>refuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tywin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21475</th>\n",
       "      <td>chastely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21476</th>\n",
       "      <td>bares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21477</th>\n",
       "      <td>perching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>incredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21479</th>\n",
       "      <td>creasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21480</th>\n",
       "      <td>exceed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21481</th>\n",
       "      <td>liegeman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21482</th>\n",
       "      <td>jayn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21483</th>\n",
       "      <td>jiggered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21484</th>\n",
       "      <td>korra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21485</th>\n",
       "      <td>jezhene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21486</th>\n",
       "      <td>betters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21487</th>\n",
       "      <td>compass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21488</th>\n",
       "      <td>unroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21489</th>\n",
       "      <td>eightyear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21490</th>\n",
       "      <td>waterfowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21491</th>\n",
       "      <td>merlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21492</th>\n",
       "      <td>peregrine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21493</th>\n",
       "      <td>liquor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21494</th>\n",
       "      <td>undressing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21495</th>\n",
       "      <td>dogtail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21496</th>\n",
       "      <td>slivers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21497</th>\n",
       "      <td>nursey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21498</th>\n",
       "      <td>shitwater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21499</th>\n",
       "      <td>implicitly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21500</th>\n",
       "      <td>spavined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21501</th>\n",
       "      <td>conray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21502</th>\n",
       "      <td>cuckold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21503</th>\n",
       "      <td>frisky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21504</th>\n",
       "      <td>luckier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21505 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0             she\n",
       "1           would\n",
       "2            have\n",
       "3            been\n",
       "4              my\n",
       "5        daughter\n",
       "6               ,\n",
       "7              if\n",
       "8             the\n",
       "9             mad\n",
       "10           king\n",
       "11            had\n",
       "12            not\n",
       "13         played\n",
       "14            his\n",
       "15          cruel\n",
       "16           jape\n",
       "17             on\n",
       "18         father\n",
       "19              .\n",
       "20             it\n",
       "21             to\n",
       "22        madness\n",
       "23           that\n",
       "24            led\n",
       "25          aerys\n",
       "26         refuse\n",
       "27           lord\n",
       "28          tywin\n",
       "29              ’\n",
       "...           ...\n",
       "21475    chastely\n",
       "21476       bares\n",
       "21477    perching\n",
       "21478  incredible\n",
       "21479    creasing\n",
       "21480      exceed\n",
       "21481    liegeman\n",
       "21482        jayn\n",
       "21483    jiggered\n",
       "21484       korra\n",
       "21485     jezhene\n",
       "21486     betters\n",
       "21487     compass\n",
       "21488      unroll\n",
       "21489   eightyear\n",
       "21490   waterfowl\n",
       "21491      merlin\n",
       "21492   peregrine\n",
       "21493      liquor\n",
       "21494  undressing\n",
       "21495     dogtail\n",
       "21496     slivers\n",
       "21497      nursey\n",
       "21498   shitwater\n",
       "21499  implicitly\n",
       "21500    spavined\n",
       "21501      conray\n",
       "21502     cuckold\n",
       "21503      frisky\n",
       "21504     luckier\n",
       "\n",
       "[21505 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_probs['word'] = word_scores.keys()\n",
    "word_probs['sampling_prob'] = word_probs.word.map(lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
