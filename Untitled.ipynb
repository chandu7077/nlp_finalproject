{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python import pywrap_tensorflow\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = Path('model/base_5000/model.ckpt-3000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader1 = pywrap_tensorflow.NewCheckpointReader(str(checkpoint_file.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step []\n",
      "classifier/output_weights/adam_m [5, 768]\n",
      "classifier/output_weights [5, 768]\n",
      "classifier/output_bias/adam_m [5]\n",
      "classifier/output_bias [5]\n",
      "bert/pooler/dense/kernel [768, 768]\n",
      "bert/pooler/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_9/output/dense/kernel/adam_v [3072, 768]\n",
      "classifier/output_weights/adam_v [5, 768]\n",
      "bert/encoder/layer_9/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_9/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_9/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_9/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_9/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_9/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_9/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_9/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_9/attention/self/value/bias [768]\n",
      "bert/encoder/layer_9/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_9/attention/self/query/bias/adam_m [768]\n",
      "bert/encoder/layer_9/attention/self/query/bias [768]\n",
      "bert/encoder/layer_9/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_9/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_9/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_9/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_9/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_9/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_8/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_9/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_8/output/dense/kernel [3072, 768]\n",
      "bert/encoder/layer_8/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_8/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_8/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_8/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_8/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/pooler/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_8/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_8/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_8/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_8/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_8/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_8/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_8/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_8/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_8/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_8/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_8/attention/self/query/bias [768]\n",
      "bert/encoder/layer_8/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_8/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_8/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_9/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_8/attention/self/key/bias [768]\n",
      "bert/encoder/layer_8/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_8/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_8/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_8/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_7/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_7/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_7/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_7/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_7/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_7/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_7/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_7/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_7/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_7/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_7/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_7/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_7/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_7/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_7/attention/self/query/bias [768]\n",
      "bert/encoder/layer_7/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_7/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_7/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_9/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_7/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_7/attention/self/key/bias [768]\n",
      "bert/encoder/layer_7/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_7/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_7/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_7/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_6/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_6/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_6/output/dense/kernel [3072, 768]\n",
      "bert/pooler/dense/bias [768]\n",
      "bert/encoder/layer_8/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_6/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_6/output/dense/bias [768]\n",
      "bert/encoder/layer_6/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_7/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_6/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_6/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_6/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_6/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_6/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_6/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_6/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_6/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_6/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_7/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_6/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_7/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_6/attention/self/value/bias [768]\n",
      "bert/encoder/layer_8/attention/self/query/bias/adam_m [768]\n",
      "bert/encoder/layer_6/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_6/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_6/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_6/attention/self/query/bias [768]\n",
      "bert/encoder/layer_6/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_6/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_6/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_6/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_6/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_6/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_6/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_6/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_6/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_6/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_8/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_7/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_5/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_0/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_5/output/dense/kernel [3072, 768]\n",
      "bert/encoder/layer_4/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_10/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_5/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_5/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_5/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_5/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_5/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_3/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_5/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_7/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_5/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_5/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_10/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_5/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_11/attention/self/value/bias [768]\n",
      "bert/encoder/layer_5/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_1/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_5/attention/self/query/bias [768]\n",
      "bert/encoder/layer_5/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_1/attention/self/key/bias [768]\n",
      "bert/encoder/layer_1/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_5/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_8/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_5/attention/self/key/bias [768]\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_5/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_4/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_4/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_4/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_4/output/dense/bias [768]\n",
      "bert/encoder/layer_0/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_4/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_4/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_4/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_4/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_9/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_3/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_5/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_5/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_4/intermediate/dense/kernel [768, 3072]\n",
      "bert/pooler/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_4/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_4/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_4/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_2/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_4/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_0/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_4/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_9/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_4/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_9/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_5/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_4/attention/self/query/bias [768]\n",
      "bert/encoder/layer_4/attention/self/key/kernel/adam_v [768, 768]\n",
      "classifier/output_bias/adam_v [5]\n",
      "bert/encoder/layer_2/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_3/output/dense/bias [768]\n",
      "bert/encoder/layer_5/output/dense/bias [768]\n",
      "bert/encoder/layer_4/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_10/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_4/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_9/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_5/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_4/attention/self/key/bias [768]\n",
      "bert/encoder/layer_3/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_4/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_4/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_4/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_9/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_0/attention/self/query/bias [768]\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_2/attention/self/query/bias/adam_m [768]\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_8/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_3/output/dense/kernel [3072, 768]\n",
      "bert/encoder/layer_8/attention/self/value/bias [768]\n",
      "bert/encoder/layer_3/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_2/attention/self/key/bias [768]\n",
      "bert/encoder/layer_3/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_3/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_3/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_9/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_3/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_3/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_3/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_3/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_3/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_6/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_3/attention/self/value/bias [768]\n",
      "bert/encoder/layer_3/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_9/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_3/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_3/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_3/attention/self/query/bias/adam_m [768]\n",
      "bert/encoder/layer_3/attention/self/query/bias [768]\n",
      "bert/encoder/layer_0/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_3/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_5/output/LayerNorm/beta/adam_m [768]\n",
      "bert/embeddings/token_type_embeddings/adam_m [2, 768]\n",
      "bert/encoder/layer_1/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_3/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_5/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_9/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_3/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_4/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_3/attention/self/key/bias [768]\n",
      "bert/encoder/layer_3/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_3/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_1/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_3/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_1/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_11/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_2/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_2/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_2/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_2/output/dense/kernel [3072, 768]\n",
      "bert/encoder/layer_6/attention/self/key/bias [768]\n",
      "bert/encoder/layer_11/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_11/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_2/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_2/output/dense/bias [768]\n",
      "bert/encoder/layer_2/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_4/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_2/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_0/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_2/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_4/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_2/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_1/attention/self/query/bias/adam_m [768]\n",
      "bert/encoder/layer_2/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_9/output/dense/kernel [3072, 768]\n",
      "bert/encoder/layer_7/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_2/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_5/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_7/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_2/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_9/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_2/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_0/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_5/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_2/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_6/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_2/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_9/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_2/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_2/attention/self/query/bias [768]\n",
      "bert/encoder/layer_2/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_11/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_2/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_2/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_2/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_11/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_2/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_6/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_0/attention/self/query/bias/adam_m [768]\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_3/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_5/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_7/output/dense/bias [768]\n",
      "bert/encoder/layer_2/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_5/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_11/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_5/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_11/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_11/output/dense/kernel [3072, 768]\n",
      "bert/encoder/layer_4/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_11/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_11/output/dense/bias [768]\n",
      "bert/encoder/layer_5/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_11/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_10/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_0/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_11/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_0/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_11/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_9/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_11/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_10/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_4/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_11/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_11/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_8/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_11/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_8/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_11/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_11/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_6/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_11/attention/self/query/bias [768]\n",
      "bert/encoder/layer_11/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_4/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_10/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_11/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_10/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_6/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_10/attention/self/query/bias [768]\n",
      "bert/encoder/layer_1/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_11/attention/self/key/bias [768]\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_11/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_5/attention/self/value/bias/adam_v [768]\n",
      "bert/embeddings/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_2/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_11/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_11/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_10/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_2/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_3/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_10/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_10/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_3/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_10/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_10/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_11/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_10/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_10/attention/self/value/bias [768]\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_11/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_5/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_11/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_4/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_1/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_6/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_10/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_10/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_3/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_4/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_8/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_10/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_10/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_3/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_1/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_10/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_1/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_5/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_11/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_10/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_11/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_10/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_0/output/dense/kernel [3072, 768]\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_0/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_7/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_0/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_5/attention/self/value/bias [768]\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_9/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_2/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_11/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_9/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_1/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_7/output/dense/kernel [3072, 768]\n",
      "bert/encoder/layer_5/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_1/output/dense/kernel/adam_m [3072, 768]\n",
      "bert/encoder/layer_1/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_10/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_1/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_10/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_4/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_10/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_1/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_7/attention/self/value/bias [768]\n",
      "bert/encoder/layer_1/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_2/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_0/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_0/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_11/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_10/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_10/attention/self/query/bias/adam_m [768]\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_0/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_4/attention/self/value/bias [768]\n",
      "bert/encoder/layer_8/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_1/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_10/attention/self/query/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_1/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_0/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_10/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_1/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_3/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_0/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_9/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_1/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_1/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_1/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_8/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_5/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_2/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_1/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/embeddings/LayerNorm/beta [768]\n",
      "bert/encoder/layer_1/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_4/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/embeddings/word_embeddings/adam_m [30522, 768]\n",
      "bert/encoder/layer_1/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/embeddings/word_embeddings [30522, 768]\n",
      "bert/encoder/layer_11/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_1/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_10/attention/self/key/bias [768]\n",
      "bert/encoder/layer_1/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_3/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_1/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_11/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_1/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_2/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_8/output/dense/bias [768]\n",
      "bert/encoder/layer_0/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_5/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_5/attention/self/query/bias/adam_m [768]\n",
      "bert/pooler/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_5/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_1/output/dense/kernel [3072, 768]\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_10/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_3/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_10/output/dense/bias [768]\n",
      "bert/encoder/layer_6/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_0/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_9/attention/self/key/bias [768]\n",
      "bert/encoder/layer_2/attention/self/value/bias [768]\n",
      "bert/encoder/layer_1/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_0/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_8/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_0/attention/self/value/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_2/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_0/attention/output/dense/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_1/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_4/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_5/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_1/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_3/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_8/attention/self/query/kernel [768, 768]\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/embeddings/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_0/attention/self/key/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_11/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_3/attention/self/value/bias/adam_m [768]\n",
      "bert/encoder/layer_0/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_7/attention/self/key/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_3/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_7/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_10/attention/self/query/kernel/adam_v [768, 768]\n",
      "bert/embeddings/token_type_embeddings [2, 768]\n",
      "bert/encoder/layer_0/attention/self/key/bias [768]\n",
      "bert/encoder/layer_0/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_1/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_2/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_0/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_9/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_2/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_9/output/dense/bias [768]\n",
      "bert/encoder/layer_2/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_0/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_0/output/dense/bias [768]\n",
      "bert/encoder/layer_0/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_3/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_0/attention/self/value/kernel [768, 768]\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_7/intermediate/dense/bias/adam_m [3072]\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m [768]\n",
      "bert/encoder/layer_10/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_4/output/dense/kernel [3072, 768]\n",
      "bert/encoder/layer_3/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_0/intermediate/dense/bias/adam_v [3072]\n",
      "bert/embeddings/position_embeddings/adam_v [512, 768]\n",
      "bert/encoder/layer_8/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_10/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_0/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_0/attention/self/query/bias/adam_v [768]\n",
      "bert/encoder/layer_6/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_4/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_7/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_7/attention/self/query/bias/adam_m [768]\n",
      "bert/encoder/layer_0/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_1/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_5/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_10/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_0/attention/self/key/bias/adam_v [768]\n",
      "bert/encoder/layer_1/intermediate/dense/kernel [768, 3072]\n",
      "bert/encoder/layer_0/intermediate/dense/bias [3072]\n",
      "bert/encoder/layer_2/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_1/attention/output/dense/bias/adam_m [768]\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_3/output/LayerNorm/gamma [768]\n",
      "bert/embeddings/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_1/attention/self/value/bias/adam_v [768]\n",
      "bert/encoder/layer_0/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_6/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_10/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_11/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_11/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_8/attention/self/key/kernel [768, 768]\n",
      "bert/encoder/layer_11/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_10/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_2/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_0/attention/output/dense/kernel [768, 768]\n",
      "bert/encoder/layer_6/attention/self/query/bias/adam_m [768]\n",
      "bert/encoder/layer_4/attention/self/query/bias/adam_m [768]\n",
      "bert/embeddings/token_type_embeddings/adam_v [2, 768]\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_1/attention/self/query/bias [768]\n",
      "bert/encoder/layer_11/attention/self/key/bias/adam_m [768]\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v [768]\n",
      "bert/encoder/layer_10/attention/output/dense/bias [768]\n",
      "bert/embeddings/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_1/attention/self/value/bias [768]\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_10/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_10/intermediate/dense/bias/adam_v [3072]\n",
      "bert/encoder/layer_1/output/dense/bias [768]\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/gamma [768]\n",
      "bert/embeddings/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_4/attention/output/dense/bias/adam_v [768]\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m [768]\n",
      "bert/encoder/layer_7/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_4/intermediate/dense/kernel/adam_v [768, 3072]\n",
      "bert/encoder/layer_10/output/dense/kernel [3072, 768]\n",
      "bert/embeddings/position_embeddings/adam_m [512, 768]\n",
      "bert/encoder/layer_9/attention/output/dense/bias [768]\n",
      "bert/encoder/layer_0/attention/self/value/bias [768]\n",
      "bert/encoder/layer_11/attention/self/query/bias/adam_m [768]\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v [768]\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_7/intermediate/dense/kernel/adam_m [768, 3072]\n",
      "bert/encoder/layer_3/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_9/output/LayerNorm/gamma [768]\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/beta [768]\n",
      "bert/encoder/layer_5/attention/output/dense/kernel/adam_v [768, 768]\n",
      "bert/encoder/layer_2/output/dense/kernel/adam_v [3072, 768]\n",
      "bert/encoder/layer_4/attention/output/dense/bias/adam_m [768]\n",
      "bert/embeddings/position_embeddings [512, 768]\n",
      "bert/encoder/layer_0/attention/self/value/kernel/adam_m [768, 768]\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/gamma [768]\n",
      "bert/embeddings/word_embeddings/adam_v [30522, 768]\n"
     ]
    }
   ],
   "source": [
    "var_to_shape_map1 = reader1.get_variable_to_shape_map()\n",
    "tensors = [key for key in var_to_shape_map1]\n",
    "for tensor in tensors:\n",
    "    print(tensor, var_to_shape_map1[tensor])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader1.get_variable_to_dtype_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf114",
   "language": "python",
   "name": "tf114"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
