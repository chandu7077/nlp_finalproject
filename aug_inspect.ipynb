{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation Inspection\n",
    "This notebook is used to sample the augmented training data and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import pandas as pd\n",
    "from utils import tokenization\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths to the Different Data Augmentation Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_base_path = './Data/proc_Data/GoT/unsup'\n",
    "prob_factors = np.arange(0.1,0.2,0.1)\n",
    "copy_number = '0'\n",
    "data_record_paths = [os.path.join(data_base_path, 'tf_idf-{:0.1f}'.format(x), copy_number, \"tf_examples.tfrecord*\") for x in prob_factors]\n",
    "data_files = [tf.contrib.slim.parallel_reader.get_data_files(\n",
    "          data_record_path) for data_record_path in data_record_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Specifications is a mapping of the different \"columns\" of data stored in the tfrecords files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 128\n",
    "feature_specs = collections.OrderedDict()\n",
    "feature_specs[\"ori_input_ids\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "feature_specs[\"ori_input_mask\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "feature_specs[\"ori_input_type_ids\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "feature_specs[\"aug_input_ids\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "feature_specs[\"aug_input_mask\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "feature_specs[\"aug_input_type_ids\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the cell below to create mappings of words to ids and ids to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = \"./bert_pretrained/bert_base/vocab.txt\"\n",
    "\n",
    "vocab = tokenization.load_vocab(vocab_file)\n",
    "ids_dict = tokenization.load_ids(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-c7e0245dd6c5>:2: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "Original Sequence:\n",
      " [CLS] brien ##ne was moving , slow and wary , sword to hand ; step , turn , and listen . each step made a little splash . a cave lion ? dire ##wo ##lves ? some bear ? tell me , jaime . what lives here ? what lives in the darkness ? doom . no bear , he knew . no lion . only doom . in the cool silvery - blue light of the swords , the big wen ##ch looked pale and fierce . i mis ##like this place . i ’ m not fond of it myself . their blades made a little island of light , but all around them stretched a sea of darkness , une ##nding . [SEP] [PAD] [PAD]\n",
      "\n",
      "\n",
      "Augmented Sequence with p=0.1:\n",
      " [CLS] moving , slow and wary , sword to hand ; step , turn , and listen figured bath ##house step made a wrists splash gods ##way a cave lion ? dire ##wo ##lves ? some bear ? tell tap , jaime . what lives here ? what lives in ( darkness trees doom . no bear , he knew . no moaning . only doom . in the cool silvery - blue light of the swords , the big wen ##ch looked pale and fierce . i mis ##like this place . i ’ una ##fra ##id not fond of it myself . their enough made a little da ##bbed of light , but all around them stretched grandfather sea pepper darkness , une ##nding . [SEP]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,infile in enumerate(data_files):\n",
    "    for example in tf.python_io.tf_record_iterator(infile[-1]):\n",
    "        a = tf.train.Example.FromString(example)\n",
    "        orig_int_list = [a.features.feature['ori_input_ids'].int64_list.value[i] for i in range(0,128)]\n",
    "        aug_int_list = [a.features.feature['aug_input_ids'].int64_list.value[i] for i in range(0,128)]\n",
    "        orig_seq = tokenization.convert_ids_to_words(orig_int_list, ids_dict)\n",
    "        aug_seq = tokenization.convert_ids_to_words(aug_int_list, ids_dict)\n",
    "        print(\"Original Sequence:\\n {}\\n\\n\".format(\" \".join(orig_seq)))\n",
    "        print(\"Augmented Sequence with p={}:\\n {}\\n\\n\".format(prob_factors[i], \" \".join(aug_seq)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(zip(orig_int_list, aug_int_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Consistent Training Examples for Baseline\n",
    "For our baseline model, we would like to use the same exact examples as we will be using in BERT finetune and the UDA modeling. For this reason we use the code below to read the examples from the tf records files and save the tokenized sequences back to a pickle file. We will then use these pickle files as input (after reading in with pandas) for our baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_path = './Data/proc_Data/GoT/test/'\n",
    "data_record_path = os.path.join(data_base_path, \"tf_examples.tfrecord*\")\n",
    "data_files = tf.contrib.slim.parallel_reader.get_data_files(\n",
    "          data_record_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 128\n",
    "feature_specs = collections.OrderedDict()\n",
    "feature_specs[\"input_ids\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "feature_specs[\"input_mask\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "feature_specs[\"input_type_ids\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "feature_specs[\"label_ids\"] = tf.io.FixedLenFeature([1], tf.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "seqs = []\n",
    "for i,infile in enumerate(data_files):\n",
    "    for example in tf.python_io.tf_record_iterator(infile):\n",
    "        a = tf.train.Example.FromString(example)\n",
    "        temp_labels = a.features.feature['label_ids'].int64_list.value[0]\n",
    "        orig_int_list = [a.features.feature['input_ids'].int64_list.value[i] for i in range(0,128)]\n",
    "        orig_seq = tokenization.convert_ids_to_words(orig_int_list, ids_dict)\n",
    "        labels.append(temp_labels)\n",
    "        seqs.append(orig_seq)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each list of tokens to one string\n",
    "seqs = [\" \".join(seq) for seq in seqs]\n",
    "\n",
    "# Convert the label ids back to book labels\n",
    "labels = np.array(labels) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['seq'] = seqs\n",
    "df['label'] = labels\n",
    "df.to_pickle(os.path.join(data_base_path,'test.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the XLNet TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_spmodel = \"./xlnet_pretrained/xlnet_base/spiece.model\"\n",
    "\n",
    "xl_features = collections.OrderedDict()\n",
    "xl_features[\"input_ids\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "xl_features[\"input_mask\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "xl_features[\"segment_ids\"] = tf.io.FixedLenFeature([max_seq_len], tf.int64)\n",
    "xl_features[\"label_ids\"] = tf.io.FixedLenFeature([1], tf.int64)\n",
    "xl_features[\"is_real_example\"] = tf.io.FixedLenFeature([1], tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(xl_spmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old.spiece.model.len-128.train.tf_record\n",
      "tf_examples.tfrecord.0.0\n"
     ]
    }
   ],
   "source": [
    "!ls ./Data/proc_Data/GoT_xlnet/train_20/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_data_base_path = './Data/proc_Data/GoT_xlnet/test/'\n",
    "xl_data_record_path = os.path.join(xl_data_base_path, \"tf_examples.tfrecord*\")\n",
    "xl_data_files = tf.contrib.slim.parallel_reader.get_data_files(\n",
    "          xl_data_record_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "seqs = []\n",
    "for i,infile in enumerate(xl_data_files):\n",
    "    for example in tf.python_io.tf_record_iterator(infile):\n",
    "        a = tf.train.Example.FromString(example)\n",
    "        id_list = [a.features.feature['input_ids'].int64_list.value[i] for i in range(0,128)]\n",
    "        label = [a.features.feature['label_ids'].int64_list.value[i] for i in range(0,1)]\n",
    "        labels.append(label[0]+1)\n",
    "        mask = [a.features.feature['input_mask'].float_list.value[i] for i in range(0,128)]\n",
    "        piece_list = [sp.IdToPiece(i) for i in id_list]\n",
    "        seqs.append(piece_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1938"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each list of tokens to one string\n",
    "seqs = [\" \".join(piece) for piece in seqs]\n",
    "\n",
    "xldf = pd.DataFrame()\n",
    "xldf['seq'] = seqs\n",
    "xldf['label'] = labels\n",
    "xldf.to_pickle(os.path.join(xl_data_base_path,'test.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check data didn't change\n",
    "I made some changes to the XLNet preprocessing to be more consistent with BERT preprocessing. The cells below should return the same as the cells above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_data_base_path = './Data/proc_Data/GoT_xlnet/train_20/'\n",
    "xl_data_record_path = os.path.join(xl_data_base_path, \"spiece.model.len-128.train.tf_record\")\n",
    "xl_data_files = tf.contrib.slim.parallel_reader.get_data_files(\n",
    "          xl_data_record_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> ▁Gen dry ’ s ▁mare ▁lost ▁her ▁footing ▁in ▁the ▁mud ▁once , ▁going ▁down ▁hard ▁on ▁her ▁hind quarter s ▁and ▁spilling ▁him ▁from ▁the ▁saddle , ▁but ▁neither ▁horse ▁nor ▁rider ▁was ▁hurt , ▁and ▁Gen dry ▁got ▁that ▁stubborn ▁look ▁on ▁his ▁face ▁and ▁mounted ▁right ▁up ▁again . ▁Not ▁long ▁after , ▁they ▁came ▁upon ▁three ▁wolves ▁devour ing ▁the ▁corpse ▁of ▁a ▁f awn . ▁When ▁Hot ▁Pie ’ s ▁horse ▁caught ▁the ▁scent , ▁he ▁ shi ed ▁and ▁bolt ed . ▁Two ▁of ▁the ▁wolves ▁fled ▁as ▁well , ▁but ▁the ▁third ▁raised ▁his ▁head ▁and ▁bar ed ▁his ▁teeth , ▁prepared ▁to ▁defend ▁his ▁kill . <sep> <cls>\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "seqs = []\n",
    "for i,infile in enumerate(xl_data_files):\n",
    "    for example in tf.python_io.tf_record_iterator(infile):\n",
    "        a = tf.train.Example.FromString(example)\n",
    "        id_list = [a.features.feature['input_ids'].int64_list.value[i] for i in range(0,128)]\n",
    "        label_list = [a.features.feature['label_ids'].int64_list.value[i] for i in range(0,1)]\n",
    "#         print(id_list)\n",
    "        piece_list = [sp.IdToPiece(i) for i in id_list]\n",
    "        print(\" \".join(piece_list))\n",
    "        print(label_list)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at augmented XLNet Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sequence:\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> ▁It ▁was ▁strangely ▁comforting ▁to ▁see ▁Ed d ’ s ▁do ur ▁face ▁again . ▁How ▁goes ▁the ▁restoration ▁work ? ▁he ▁asked ▁his ▁old ▁steward . ▁Ten ▁more ▁years ▁should ▁do ▁it , ▁Tol lett ▁replied ▁in ▁his ▁usual ▁gloomy ▁tone . ▁Place ▁was ▁over run ▁with ▁rats ▁when ▁we ▁moved ▁in . ▁The ▁spear wi ve s ▁killed ▁the ▁nasty ▁bug gers . ▁Now ▁the ▁place ▁is ▁over run ▁with ▁spear wi ve s . ▁There ’ s ▁days ▁I ▁want ▁the ▁rats ▁back . ▁How ▁do ▁you ▁find ▁serving ▁under ▁Iron ▁Em met t ? ▁Jon ▁asked . ▁Most ly ▁it ’ s ▁Black ▁Mari s ▁serving ▁under ▁him , ▁ m ’ lord . <sep> <cls>\n",
      "\n",
      "\n",
      "Augmented Sequence with p=0.1:\n",
      " ▁It ▁was ▁strangely ▁comforting ▁to ▁see ▁Ed d ▁ ’ ▁ s ▁do ur ▁face ▁again ▁Owen ▁How ▁goes ▁the ▁restoration ▁work ▁ ? ▁he ▁handled ▁his ▁old ▁steward ▁ . ▁Ten ▁more ▁years ▁should ▁do ▁it ▁ , ▁Tol lett ▁replied ▁Horn foot ▁his ▁usual ▁gloomy ▁voice ▁restrain ▁Place ▁was ▁over run ▁with ▁rats ▁O go ▁sworn ▁trembling ▁in ▁forgiven ▁The ▁spear wi ve s ▁killed ▁the ▁nasty ▁bottom ▁ . ▁Now ▁the ▁place ▁ mus k ▁over run ▁with ▁spear wi ve s ▁ . ▁There ▁ ’ ▁ s ▁days ▁I ▁want ▁the ▁rats ▁back ▁ . ▁How ▁do ▁you ▁find ▁serving ▁under ▁Iron ▁Em met t ▁ ? ▁Jon ▁asked ▁quarrel ing ▁Most ly ▁it ▁ ’ ▁ s ▁Black ▁Mari s <sep> <cls>\n",
      "\n",
      "\n",
      "Original Sequence:\n",
      " ▁No , ▁she ▁remembered ▁thinking , ▁not ▁every ▁face , ▁my ▁lord . ▁No ▁one ▁was ▁smiling ▁now . ▁The ▁looks ▁the ▁spar row s ▁gave ▁her ▁were ▁dull , ▁ s ul len , ▁hostile . ▁They ▁made ▁way ▁but ▁reluctantly . ▁If ▁they ▁were ▁truly ▁spar row s , ▁a ▁shout ▁would ▁send ▁them ▁flying . ▁A ▁hundred ▁gold ▁cloak s ▁with ▁stave s ▁and ▁sword s ▁and ▁mac es ▁could ▁clear ▁this ▁ ra bble ▁quick ▁enough . ▁That ▁was ▁what ▁Lord ▁Ty win ▁would ▁have ▁done . ▁He ▁would ▁have ▁ ridden ▁over ▁them ▁instead ▁of ▁walking ▁through . ▁When ▁she ▁saw ▁what ▁they ▁had ▁done ▁to ▁Ba el or ▁the ▁Be loved , ▁the ▁queen ▁had ▁cause ▁to ▁ ru e <sep> <cls>\n",
      "\n",
      "\n",
      "Augmented Sequence with p=0.3:\n",
      " ▁No ▁dwell ▁she ▁remembered ▁thinking ▁ , ▁worship ▁every ▁face ▁ , ▁my ▁lord ▁machines ▁No ▁one ▁was ▁smiling ▁now ▁ . ▁The ▁ t reach ery ▁the ▁spar row s ▁gave ▁see ▁were ▁dull ▁ , ▁ s ul len ▁ , ▁hostile ▁rooftop s ▁They ▁made ▁way ▁ cri pple s ▁reluctantly ▁ . ▁If ▁they ▁were ▁truly ▁spar row s ▁ , ▁a ▁shout ▁ceiling ▁send ▁them ▁flying ▁soft ness ▁tedious ▁hundred ▁gold ▁count ▁with ▁stave s ▁and ▁sword s ▁harbor s ▁mac es ▁fl ing ▁clear ▁this ▁ ra bble ▁quick ▁des tri ers ▁trees ▁That ▁was ▁what ▁Lord ▁Ty win ▁would ▁have ▁done ▁tumble ▁tired ▁would ▁have ▁To ward ▁over ▁them ▁instead ▁departed ▁walking ▁through ▁ . ▁When ▁she ▁saw ▁ <sep> <cls>\n",
      "\n",
      "\n",
      "Original Sequence:\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> ▁He ▁will , ▁San sa ▁said , ▁heart ▁soaring . ▁Oh , ▁I ▁know ▁he ▁will . ▁The ▁straw ▁on ▁the ▁floor ▁ s tank ▁of ▁urine . ▁There ▁was ▁no ▁window , ▁no ▁bed , ▁not ▁even ▁a ▁ s lop ▁bucket . ▁He ▁remembered ▁walls ▁of ▁pale ▁red ▁stone ▁ fest oon ed ▁with ▁patches ▁of ▁ nit re , ▁a ▁grey ▁door ▁of ▁splinter ed ▁wood , ▁four ▁inches ▁thick ▁and ▁ studded ▁with ▁iron . ▁He ▁had ▁seen ▁them , ▁briefly , ▁a ▁quick ▁glimpse ▁as ▁they ▁shoved ▁him ▁inside . ▁Once ▁the ▁door ▁had ▁slammed ▁shut , ▁he ▁had ▁seen ▁no ▁more . ▁The ▁dark ▁was ▁absolute . <sep> <cls>\n",
      "\n",
      "\n",
      "Augmented Sequence with p=0.5:\n",
      " ▁Feel ▁falling ▁Quick ▁San sa ▁custody ▁circle ▁heart ▁soaring ▁ . ▁trickle ▁loans ▁I ▁brown ▁shift ▁will ▁crowd ▁priests ▁un ador ned ▁stone ▁c leave d ▁roof less ▁narrowed ▁dipped ▁urine ▁I lly rio ▁flea s ▁owns ▁no ▁touch ▁ , ▁no ▁bed ▁ , ▁congratulate ▁smiling ▁And ▁ s lop ▁bucket ▁a co ly tes ▁lady ▁is ▁reading ▁bought ▁pale ▁red ▁dim ple s ▁ fest oon ed ▁steps ▁patches ▁of ▁ nit re ▁ , ▁a ▁grey ▁door ▁cheerful ly ▁splinter ed ▁wood ▁ , ▁bitch ▁inches ▁thick ▁Or ton ▁ studded ▁with ▁iron ▁ . ▁He ▁had ▁ bang ed ▁them ▁Q arth ▁briefly ▁bars ▁Then ▁quick ▁glimpse ▁as ▁moan ing ▁dragon fla me ▁so ar ▁sea shell s ▁ . ▁murders ▁the <sep> <cls>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tfidf in np.arange(0.1,0.7,0.2):\n",
    "    unsup_data_path = './Data/proc_data/GoT_xlnet/unsup/tf_idf-{:0.1f}/0/'.format(tfidf)\n",
    "    us_data_record_path = os.path.join(unsup_data_path, \"tf_examples.tfrecord*\")\n",
    "    us_data_files = tf.contrib.slim.parallel_reader.get_data_files(\n",
    "              us_data_record_path)\n",
    "    for i,infile in enumerate(us_data_files):\n",
    "        for example in tf.python_io.tf_record_iterator(infile):\n",
    "            a = tf.train.Example.FromString(example)\n",
    "\n",
    "            ori_id_list = [a.features.feature['ori_input_ids'].int64_list.value[i] for i in range(0,128)]\n",
    "            aug_id_list = [a.features.feature['aug_input_ids'].int64_list.value[i] for i in range(0,128)]\n",
    "\n",
    "            ori_piece_list = [sp.IdToPiece(i) for i in ori_id_list]\n",
    "            aug_piece_list = [sp.IdToPiece(i) for i in aug_id_list]\n",
    "\n",
    "            ori_mask_list = [a.features.feature['ori_input_mask'].float_list.value[i] for i in range(0,128)]\n",
    "            aug_mask_list = [a.features.feature['aug_input_mask'].float_list.value[i] for i in range(0,128)]\n",
    "\n",
    "            print(\"Original Sequence:\\n {}\\n\\n\".format(\" \".join(ori_piece_list)))\n",
    "            print(\"Augmented Sequence with p={:0.1f}:\\n {}\\n\\n\".format(tfidf, \" \".join(aug_piece_list)))\n",
    "            break\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sequence:\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> ▁It ▁was ▁strangely ▁comforting ▁to ▁see ▁Ed d ’ s ▁do ur ▁face ▁again . ▁How ▁goes ▁the ▁restoration ▁work ? ▁he ▁asked ▁his ▁old ▁steward . ▁Ten ▁more ▁years ▁should ▁do ▁it , ▁Tol lett ▁replied ▁in ▁his ▁usual ▁gloomy ▁tone . ▁Place ▁was ▁over run ▁with ▁rats ▁when ▁we ▁moved ▁in . ▁The ▁spear wi ve s ▁killed ▁the ▁nasty ▁bug gers . ▁Now ▁the ▁place ▁is ▁over run ▁with ▁spear wi ve s . ▁There ’ s ▁days ▁I ▁want ▁the ▁rats ▁back . ▁How ▁do ▁you ▁find ▁serving ▁under ▁Iron ▁Em met t ? ▁Jon ▁asked . ▁Most ly ▁it ’ s ▁Black ▁Mari s ▁serving ▁under ▁him , ▁ m ’ lord . <sep> <cls>\n",
      "\n",
      "\n",
      "Augmented Sequence with p=0.1:\n",
      " ▁It ▁was ▁strangely ▁comforting ▁to ▁see ▁Ed d ▁ ’ ▁ s ▁do ur ▁face ▁again ▁Owen ▁How ▁goes ▁the ▁restoration ▁work ▁ ? ▁he ▁handled ▁his ▁old ▁steward ▁ . ▁Ten ▁more ▁years ▁should ▁do ▁it ▁ , ▁Tol lett ▁replied ▁Horn foot ▁his ▁usual ▁gloomy ▁voice ▁restrain ▁Place ▁was ▁over run ▁with ▁rats ▁O go ▁sworn ▁trembling ▁in ▁forgiven ▁The ▁spear wi ve s ▁killed ▁the ▁nasty ▁bottom ▁ . ▁Now ▁the ▁place ▁ mus k ▁over run ▁with ▁spear wi ve s ▁ . ▁There ▁ ’ ▁ s ▁days ▁I ▁want ▁the ▁rats ▁back ▁ . ▁How ▁do ▁you ▁find ▁serving ▁under ▁Iron ▁Em met t ▁ ? ▁Jon ▁asked ▁quarrel ing ▁Most ly ▁it ▁ ’ ▁ s ▁Black ▁Mari s <sep> <cls>\n",
      "\n",
      "\n",
      "Original Sequence:\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> ▁I ▁wanted ▁him ▁to ▁come ▁himself . ▁She ▁crushed ▁Lord ▁Ty win ’ s ▁letter ▁in ▁her ▁fingers . ▁I ▁am ▁J off rey ’ s ▁regent , ▁and ▁I ▁sent ▁him ▁a ▁royal ▁command ! ▁And ▁he ▁ignored ▁you , ▁Ty rion ▁pointed ▁out . ▁He ▁has ▁quite ▁a ▁large ▁army , ▁he ▁can ▁do ▁that . ▁Nor ▁is ▁he ▁the ▁first . ▁I s ▁he ? ▁Cer s ei ’ s ▁mouth ▁tightened . ▁He ▁could ▁see ▁her ▁color ▁rising . ▁If ▁I ▁name ▁this ▁letter ▁a ▁forgery ▁and ▁tell ▁them ▁to ▁throw ▁you ▁in ▁a ▁dungeon , ▁no ▁one ▁will ▁ignore ▁that , ▁I ▁promise ▁you . <sep> <cls>\n",
      "\n",
      "\n",
      "Augmented Sequence with p=0.1:\n",
      " ▁I ▁healed ▁him ▁to ▁come ▁himself ▁ . ▁She ▁crushed ▁hour ▁Ty win ▁ ’ ▁ s ▁letter ▁in ▁her ▁fingers ▁ . ▁I ▁am ▁J off rey ▁ ’ ▁ s ▁regent ▁ , ▁and ▁I ▁sent ▁him ▁a ▁royal ▁command ▁ ! ▁spear man ▁he ▁ignored ▁you ▁ , ▁Ty rion ▁pointed ▁out ▁ . ▁He ▁has ▁quite ▁a ▁large ▁army ▁Lamp s ▁he ▁can ▁do ▁that ▁ . ▁Nor ▁is ▁he ▁the ▁Mol len ▁ . ▁I s ▁lifted ▁ ? ▁Cer s ei ▁ ’ ▁reduced ▁mouth ▁tightened ▁ . ▁He ▁been ▁see ▁her ▁color ▁rising ▁ . ▁If ▁I ▁name ▁this ▁letter ▁a ▁forgery ▁and ▁tell ▁weakest ▁to ▁throw ▁you ▁in ▁a ▁dungeon ▁ , ▁no ▁one ▁will ▁ignore ▁that ▁ <sep> <cls>\n",
      "\n",
      "\n",
      "Original Sequence:\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> ▁When ▁he ▁removed ▁his ▁ helm , ▁San sa ▁saw ▁that ▁he ▁was ▁an ▁old ▁man ▁with ▁hair ▁as ▁pale ▁as ▁his ▁armor , ▁yet ▁he ▁seemed ▁strong ▁and ▁graceful ▁for ▁all ▁that . ▁From ▁his ▁shoulders ▁hung ▁the ▁pure ▁white ▁cloak ▁of ▁the ▁Kings guard . ▁His ▁companion ▁was ▁a ▁man ▁near ▁twenty ▁whose ▁armor ▁was ▁steel ▁plate ▁of ▁a ▁deep ▁forest green . ▁He ▁was ▁the ▁handsome st ▁man ▁San sa ▁had ▁ever ▁set ▁eyes ▁upon ; ▁tall ▁and ▁powerful ly ▁made , ▁with ▁jet - black ▁hair ▁that ▁fell ▁to ▁his ▁shoulders ▁and ▁framed ▁a ▁clean - s haven ▁face , ▁and ▁laughing ▁green ▁eyes ▁to ▁match ▁his ▁armor . <sep> <cls>\n",
      "\n",
      "\n",
      "Augmented Sequence with p=0.1:\n",
      " ▁When ▁he ▁Pie ▁his ▁flew ▁ , ▁San sa ▁ radi she s ▁that ▁he ▁was ▁an ▁old ▁man ▁with ▁And ▁as ▁pale ▁as ▁his ▁armor ▁ , ▁yet ▁he ▁seemed ▁strong ▁and ▁graceful ▁heads man ▁all ▁that ▁ . ▁From ▁his ▁shoulders ▁Ar no lf ▁tune ▁pure ▁white ▁dubbed ▁of ▁the ▁Kings guard ▁ . ▁His ▁companion ▁spurred ▁a ▁man ▁near ▁twenty ▁Sea stone ▁armor ▁was ▁steel ▁plate ▁of ▁a ▁deep ▁forest green ▁peer ▁smart ly ▁was ▁the ▁handsome st ▁man ▁San sa ▁had ▁ever ▁set ▁eyes ▁upon ▁ ; ▁tall ▁and ▁powerful ly ▁made ▁ , ▁with ▁jet ▁ - ▁black ▁hair ▁that ▁fell ▁to ▁his ▁shoulders ▁and ▁framed ▁a ▁clean ▁ - ▁ s haven ▁face ▁ , ▁Tom ▁laughing ▁green ▁eyes ▁to <sep> <cls>\n",
      "\n",
      "\n",
      "Original Sequence:\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> ▁Our ▁bodies ▁betray ▁even ▁the ▁noble st ▁of ▁us . ▁He ▁thought ▁of ▁King ▁Ba el or ▁the ▁Blessed , ▁who ▁would ▁fast ▁to ▁the ▁point ▁of ▁faint ing ▁to ▁tame ▁the ▁lust s ▁that ▁shame d ▁him . ▁Must ▁he ▁do ▁the ▁same ? ▁A ▁short ▁man ▁stood ▁in ▁an ▁arched ▁doorway ▁grill ing ▁chunk s ▁of ▁snake ▁over ▁a ▁bra zier , ▁turning ▁them ▁with ▁wooden ▁to ng s ▁as ▁they ▁crisp ed . ▁The ▁ pun gent ▁smell ▁of ▁his ▁sauce s ▁brought ▁tears ▁to ▁the ▁knight ’ s ▁eyes . ▁The ▁best ▁snake ▁sauce ▁had ▁a ▁drop ▁of ▁venom ▁in ▁it , ▁he ▁had ▁heard , ▁along ▁with ▁mustard ▁seeds ▁and ▁dragon ▁pepper s . <sep> <cls>\n",
      "\n",
      "\n",
      "Augmented Sequence with p=0.1:\n",
      " ▁Our ▁bodies ▁betray ▁even ▁the ▁noble st ▁of ▁us ▁ . ▁He ▁thought ▁of ▁King ▁Ba el or ▁the ▁Blessed ▁ , ▁who ▁would ▁fast ▁to ▁the ▁point ▁of ▁faint ing ▁to ▁tame ▁the ▁lust s ▁that ▁shame d ▁him ▁crust ▁his s ing ▁stopped ▁do ▁the ▁should ▁ ? ▁splendid ▁short ▁man ▁stood ▁in ▁an ▁arched ▁doorway ▁grill ing ▁volume ▁of ▁snake ▁over ▁a ▁bra zier ▁ , ▁turning ▁Cal e otte ▁with ▁wooden ▁to ng s ▁mirrors ▁they ▁crisp ed ▁ . ▁The ▁ pun gent ▁smell ▁of ▁his ▁sauce s ▁brought ▁tears ▁to ▁the ▁knight ▁ ’ ▁ s ▁eyes ▁ . ▁The ▁best ▁snake ▁sauce ▁had ▁a ▁drop ▁of ▁venom ▁arch ▁Horse face ▁ , ▁he ▁had ▁heard ▁ , ▁along ▁with <sep> <cls>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unsup_data_path = './Data/proc_data/GoT_xlnet/unsup/tf_idf-0.1/0/'\n",
    "us_data_record_path = os.path.join(unsup_data_path, \"tf_examples.tfrecord*\")\n",
    "us_data_files = tf.contrib.slim.parallel_reader.get_data_files(\n",
    "          us_data_record_path)\n",
    "for i,infile in enumerate(us_data_files):\n",
    "    for example in tf.python_io.tf_record_iterator(infile):\n",
    "        a = tf.train.Example.FromString(example)\n",
    "        \n",
    "        ori_id_list = [a.features.feature['ori_input_ids'].int64_list.value[i] for i in range(0,128)]\n",
    "        aug_id_list = [a.features.feature['aug_input_ids'].int64_list.value[i] for i in range(0,128)]\n",
    "        \n",
    "        ori_piece_list = [sp.IdToPiece(i) for i in ori_id_list]\n",
    "        aug_piece_list = [sp.IdToPiece(i) for i in aug_id_list]\n",
    "        \n",
    "        ori_mask_list = [a.features.feature['ori_input_mask'].float_list.value[i] for i in range(0,128)]\n",
    "        aug_mask_list = [a.features.feature['aug_input_mask'].float_list.value[i] for i in range(0,128)]\n",
    "        \n",
    "        print(\"Original Sequence:\\n {}\\n\\n\".format(\" \".join(ori_piece_list)))\n",
    "        print(\"Augmented Sequence with p=0.1:\\n {}\\n\\n\".format(\" \".join(aug_piece_list)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf114",
   "language": "python",
   "name": "tf114"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
