{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QI1HwzzozfN6"
   },
   "source": [
    "# BERT Fine-Tuned Notebook\n",
    "## W266 Final Project\n",
    "### Game of Thrones Text Classification\n",
    "### T. P. Goter\n",
    "### Fall 2019\n",
    "\n",
    "This notebook is used to perform the baseline, finetuned BERT supervised text classification. The original UDA process utilized a Python script wrapped in a bash shell script. This notebook was generated in order to better show and annotate the process.\n",
    "\n",
    "## Acknowledgement\n",
    "Much of this code was leveraged from the open source [UDA](https://github.com/google-research/uda). It has been adapted to the Game of Thrones dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rDPLerl8zfN8"
   },
   "source": [
    "## Import Data Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20328,
     "status": "ok",
     "timestamp": 1572720631528,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "t5ntHu7dzfN9",
    "outputId": "becb4b84-fcce-428e-fa8a-a18acdd38275"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/optimization.py:28: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import os\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "print(tf.__version__)\n",
    "\n",
    "import yaml\n",
    "import pprint\n",
    "\n",
    "from absl import app\n",
    "from absl import logging\n",
    "\n",
    "from bert import modeling\n",
    "from utils import proc_data_utils, raw_data_utils\n",
    "import uda\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k84AiVYz_WcP"
   },
   "source": [
    "## Get BERT onto Google Drive - DO THIS ONCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1572718188533,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "EfpRHNGw_jRr",
    "outputId": "afa29e4d-f698-4d79-8cf7-037dce786957"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_model.ckpt.meta',\n",
       " 'bert_model.ckpt.data-00000-of-00001',\n",
       " 'bert_config.json',\n",
       " 'vocab.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'bert_model.ckpt.index']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! mkdir /content/drive/My\\ Drive/NLP_FinalProject/working/bert_pretrained\n",
    "# download bert base\n",
    "#! wget -P /content/drive/My\\ Drive/NLP_FinalProject/working/bert_pretrained https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "#! unzip /content/drive/My\\ Drive/NLP_FinalProject/working/bert_pretrained/uncased_L-12_H-768_A-12.zip &&\n",
    "#! rm /content/drive/My\\ Drive/NLP_FinalProject/working/bert_pretrained/uncased_L-12_H-768_A-12.zip\n",
    "#! mkdir /content/drive/My\\ Drive/NLP_FinalProject/working/bert_pretrained/bert_base\n",
    "#! mv uncased_L-12_H-768_A-12 /content/drive/My\\ Drive/NLP_FinalProject/working/bert_pretrained/bert_base\n",
    "#! mv /content/drive/My\\ Drive/NLP_FinalProject/working/bert_pretrained/bert_base/uncased*/* /content/drive/My\\ Drive/NLP_FinalProject/working/bert_pretrained/bert_base/\n",
    "os.listdir('./bert_pretrained/bert_base/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ldd5k4YSzfOB"
   },
   "source": [
    "## Define Some Options\n",
    "This section replaces passing the input parameters as command line arguments. This section is very important. It controls the entire model. See the dictionary below.\n",
    "\n",
    "### Task Options:\n",
    "- **do_train:** Boolean of whether we are training\n",
    "- **do_eval:** Boolean of whether we are just evaluating\n",
    "\n",
    "### Training Options:\n",
    "- **sup_train_data_dir:** Input directory for supervised data. This should be set to \"./Data/proc_data/train_##\" where the ## is one of the subsets of training data generated from the prepro_ALL.csh script.\n",
    "- **eval_data_dir:**  The input data dir of the evaluation data. This should be the path to the development data with which we will do hyperparameter tuning. We can change this to the test data directory once we are ready for final evaluation. The dev data path is: \"./Data/proc_data/dev\"\n",
    "- **unsup_data_dir:** The input data dir of the unsupervised data. Path for the unsupervised, augmented data. This should be equal to \"./Data/proc_data/unsup\"\n",
    "- **bert_config_file:** Absolute path to the json file corresponding to the pre-trained BERT model. For us this is: \"./bert_pretrained/bert_base/bert_config.json\"\n",
    "- **vocab_file:** The vocabulary file that the BERT model was trained on. This should be equal to \"./bert_pretrained/bert_base/vocab.txt\"\n",
    "- **init_checkpoint:** Initial checkpoint from the pre-trained BERT model. This should be equal to: \"./bert_pretrained/bert_base/bert_model.ckpt\"\n",
    "- **task_name:** The name of the task to train. This should be equal to \"GoT\"\n",
    "- **model_dir:** The output directory where the model checkpoints will be written. This will be set to \"models\" followed by a case specific identifier.\n",
    "\n",
    "### Model configuration\n",
    "- **use_one_hot_embeddings:** Boolean, default: True, If True, tf.one_hot will be used for embedding lookups, otherwise tf.nn.embedding_lookup will be used. On TPUs, this should be True since it is much faster.\"\n",
    "- **max_seq_length\":** Integer, default = 128, The maximum total sequence length after WordPiece tokenization. Sequences longer than this will be truncated, and sequences shorter than this will be padded. Note, GoT data was processed to be on-average close to this length to minimize lost data.\n",
    "- **model_dropout:** Float, default = -1 (i.e., no dropout). Dropout rate for both the attention and the hidden states.\n",
    "\n",
    "### Training hyper-parameters\n",
    "- **train_batch_size:** Integer, default = 32. Based on the discussion [here](https://github.com/google-research/bert#out-of-memory-issues). 32 is probably the largest we can run with 11 GB of RAM while using BERT base with a maximum sequence length of 128.\n",
    "- **eval_batch_size:** Integer, default = 8, \"Base batch size for evaluation.\"\n",
    "- **save_checkpoints_num:** Integer, default = 20, Number of checkpoints to save during training.\n",
    "- **iterations_per_loop:** Integer, default = 200, Number of steps to make in each estimator call.\n",
    "- **num_train_steps:** Integer, no default, number of training steps\n",
    "\n",
    "### Optimizer hyperparameters\n",
    "- **learning_rate:** Float, default = 2e-5, The initial learning rate for Adam Optimizer\n",
    "- **num_warmup_steps:** Integer, no default, Number of warmup steps\n",
    "- **clip_norm:** Float, default= 1.0, Gradient clip hyperparameter.\n",
    "\n",
    "### UDA Options:\n",
    "- **unsup_ratio:** Integer - ratio between unsupervised batch size and supervised batch size. If zero - dont use\n",
    "- **aug_ops:** String - what augmentation procedure do you want to run\n",
    "- **aug_copy:** Integer - how many augmentations per example are to be generated\n",
    "- **uda_coeff:** Float - default 1 - This is the coefficient on the UDA loss. Basically you can rely more or less on the UDA loss during the supervised training. The UDA paper generally kept this at 1\n",
    "- **tsa:** String - Annealing schedule to use. Options provided are \"\" none, linear_schedule, log_schedule, exp_schedule\n",
    "- **uda_softmax_temp:** Float, default -1, A smaller temperature will accentuate differences in probabilities. Low temps were used in the UDA paper for cases with low numbers of labeled data, after masking out uncertain predictions.\n",
    "- **uda_confidence_thresh:** Float, default -1, Threshold value above which the consistency loss term from the UDA is used. Basically ensures we are using loss from random guesses.\n",
    "\n",
    "### TPU and GPU Options:\n",
    "- **use_tpu:** Boolean - self-explanatory - it affects how the model is run. If we run in colab this could be important. False means use CPU or GPU. We will default to FALSE.\n",
    "- **tpu_name:** String - address of the tpu\n",
    "- **gcp_project:** String - project name when using TPU\n",
    "- **tpu_zone:** String - can be set or detected\n",
    "- **master:** Address of the TPU master, if applicable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ix6GcvwfzfOC"
   },
   "source": [
    "### Defaults\n",
    "\n",
    "The defaults below should not be changed. Note that a config file will be read in after this in order to update these if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f9KsUaCuzfOD"
   },
   "outputs": [],
   "source": [
    "with open('./config/defaults.yml', 'r') as def_config:\n",
    "    options = yaml.safe_load(def_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipwuwXYXzfOF"
   },
   "source": [
    "## Set the Case to Run\n",
    "This will ensure that different configurations are being controlled and saved separately. Just load in the correct yaml file that specifies all of the parameters.\n",
    "\n",
    "### Updated to include UDA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWauxwMH-UCL"
   },
   "outputs": [],
   "source": [
    "case_specifics = {'do_train': True,\n",
    "'do_eval' : True,\n",
    "'sup_train_data_dir': './Data/proc_data/GoT/train_5000',\n",
    "'eval_data_dir':  './Data/proc_data/GoT/dev',\n",
    "'bert_config_file':  './bert_pretrained/bert_base/bert_config.json',\n",
    "'vocab_file':  './bert_pretrained/bert_base/vocab.txt',\n",
    "'init_checkpoint':  './bert_pretrained/bert_base/bert_model.ckpt',\n",
    "'task_name':  'GoT',\n",
    "'model_dir':  './model/shuffle_5000_bs32_hdo15_final',\n",
    "'num_train_steps':  3000, \n",
    "'train_batch_size': 32,\n",
    "'learning_rate':  0.00003,\n",
    "'num_warmup_steps':  300, \n",
    "'hidden_dropout': 0.15,\n",
    "'attention_dropout': 0.1,\n",
    "'save_checkpoints_num' :10,\n",
    "'use_tpu' :False,\n",
    "'use_one_hot_embeddings': False   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1341,
     "status": "ok",
     "timestamp": 1572720644389,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "B-kwcvhEzfOG",
    "outputId": "5eb54f2f-476f-44e7-8e9d-bb20c2350774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Full Listing of Options: \n",
      "==================================================\n",
      "{'attention_dropout': 0.1,\n",
      " 'aug_copy': -1,\n",
      " 'aug_ops': '',\n",
      " 'bert_config_file': './bert_pretrained/bert_base/bert_config.json',\n",
      " 'clip_norm': 1.0,\n",
      " 'do_eval': True,\n",
      " 'do_train': True,\n",
      " 'eval_batch_size': 8,\n",
      " 'eval_data_dir': './Data/proc_data/GoT/dev',\n",
      " 'hidden_dropout': 0.15,\n",
      " 'init_checkpoint': './bert_pretrained/bert_base/bert_model.ckpt',\n",
      " 'iterations_per_loop': 200,\n",
      " 'learning_rate': 3e-05,\n",
      " 'max_seq_length': 128,\n",
      " 'model_dir': './model/shuffle_5000_bs32_hdo15_final',\n",
      " 'num_train_steps': 3000,\n",
      " 'num_warmup_steps': 300,\n",
      " 'save_checkpoints_num': 10,\n",
      " 'sup_train_data_dir': './Data/proc_data/GoT/train_5000',\n",
      " 'task_name': 'GoT',\n",
      " 'train_batch_size': 32,\n",
      " 'tsa': '',\n",
      " 'uda_coeff': 1,\n",
      " 'uda_confidence_thresh': -1,\n",
      " 'uda_softmax_temp': -1,\n",
      " 'unsup_data_dir': 'None',\n",
      " 'unsup_ratio': 0,\n",
      " 'use_one_hot_embeddings': False,\n",
      " 'use_tpu': False,\n",
      " 'vocab_file': './bert_pretrained/bert_base/vocab.txt'}\n"
     ]
    }
   ],
   "source": [
    "# merge dictionaries    \n",
    "options.update(case_specifics)\n",
    "\n",
    "#\n",
    "print()\n",
    "print(\"=\"*50 + \"\\nFull Listing of Options: \\n\" + \"=\"*50)\n",
    "pprint.pprint(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaK3pV8jzfOI"
   },
   "source": [
    "## Setup the Job\n",
    "This section of the code grabs the right data and reads in the BERT config file. We also dump our configuration options to a JSON file in the model directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1122,
     "status": "ok",
     "timestamp": 1572720653694,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "Fk9OUkkxzfOJ",
    "outputId": "2ae8f6d4-3019-4ca2-ebd7-30422aa8ddc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5']\n",
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/modeling.py:94: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Setting up BERT Config using data from ./bert_pretrained/bert_base/bert_config.json\n",
      "INFO:tensorflow:Setting up BERT Config using data from {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'gelu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'intermediate_size': 3072, 'max_position_embeddings': 512, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 30522}\n",
      "INFO:tensorflow:Updating FF layer dropout to 0.15\n",
      "INFO:tensorflow:Updating attention layer dropout to 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'WriteFile' type=WriteFile>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Record informational logs\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "# GoT Processor Class has methods for retrieving text/train/dev datasets\n",
    "processor = raw_data_utils.GoTProcessor()\n",
    "\n",
    "# Read in the labels\n",
    "label_list = processor.get_labels()\n",
    "\n",
    "# Check the labels  -  they should be 1 through 5\n",
    "print(label_list)\n",
    "\n",
    "# Read the BertConfig File\n",
    "bert_config = modeling.BertConfig.from_json_file(\n",
    "      options['bert_config_file'],\n",
    "      options['hidden_dropout'],\n",
    "      options['attention_dropout'])\n",
    "\n",
    "# Create the directory for the current model\n",
    "tf.io.gfile.makedirs(options['model_dir'])\n",
    "\n",
    "# Dump the configuration dictionary to an output json file in the model specific directory\n",
    "tf.io.write_file(os.path.join(options['model_dir'], \"OPTIONS.json\"), json.dumps(options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mh-GEVKgjis"
   },
   "outputs": [],
   "source": [
    "if options['use_tpu'] and tpu_address:\n",
    "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
    "      tpu_address, zone=None, project=None)\n",
    "else:\n",
    "  tpu_cluster_resolver = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTOtZNGjzfOL"
   },
   "source": [
    "## Model Specific Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1572720670469,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "mib9xn0dzfOM",
    "outputId": "ab851545-94c6-42dc-eb3e-e175fcc26324"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:warmup steps 300/3000\n",
      "INFO:absl:setting save checkpoints steps to 300\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"warmup steps {}/{}\".format(\n",
    "      options['num_warmup_steps'], options['num_train_steps']))\n",
    "\n",
    "# Specify where the checkpoints will be saved. This is just integer division between the total number of training steps and the number of checkpoints\n",
    "save_checkpoints_steps = options['num_train_steps'] // options['save_checkpoints_num']\n",
    "\n",
    "# Log the checkpoints\n",
    "logging.info(\"setting save checkpoints steps to {:d}\".format(\n",
    "      save_checkpoints_steps))\n",
    "\n",
    "# Update iterations per loop\n",
    "options['iterations_per_loop'] = min(save_checkpoints_steps,\n",
    "                                  options['iterations_per_loop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02R3jI_EzfOO"
   },
   "source": [
    "## Setup Run Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2809,
     "status": "ok",
     "timestamp": 1572720673081,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "uCpZtGTXzfOP",
    "outputId": "203a6cc9-044f-4917-e84a-6ce19111ee36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is set up for potential use with a TPU\n",
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    master=None,\n",
    "    model_dir=options['model_dir'],\n",
    "    save_checkpoints_steps=save_checkpoints_steps,\n",
    "    keep_checkpoint_max=10,\n",
    "    # train_distribute=train_distribute,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=options['iterations_per_loop'],\n",
    "        per_host_input_for_training=is_per_host))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "drHTEqu5zfOR"
   },
   "source": [
    "## Create our model\n",
    "Our model uses the bert configuration parameters as well as gets fed all of our particular running options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rvhN_jwozfOR"
   },
   "outputs": [],
   "source": [
    "model_fn = uda.model_fn_builder(\n",
    "      bert_config=bert_config,\n",
    "      init_checkpoint=options['init_checkpoint'],\n",
    "      learning_rate=options['learning_rate'],\n",
    "      clip_norm=options['clip_norm'],\n",
    "      num_train_steps=options['num_train_steps'],\n",
    "      num_warmup_steps=options['num_warmup_steps'],\n",
    "      use_tpu=options['use_tpu'],\n",
    "      use_one_hot_embeddings=options['use_one_hot_embeddings'],\n",
    "      num_labels=len(label_list),\n",
    "      unsup_ratio=options['unsup_ratio'],\n",
    "      uda_coeff=options['uda_coeff'],\n",
    "      tsa=options['tsa'],\n",
    "      uda_softmax_temp=options['uda_softmax_temp'],\n",
    "      uda_confidence_thresh=options['uda_confidence_thresh'],\n",
    "      print_feature=False,\n",
    "      print_structure=False,\n",
    "      freeze_layers = (False, )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXEG7DDBzfOU"
   },
   "source": [
    "## Create our Estimator\n",
    "Basically contains the intstructions to run the model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1572720674358,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "GVgGwY51zfOV",
    "outputId": "f403138b-c21c-4ceb-f1f3-61aa43f2f0fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './model/shuffle_5000_bs32_hdo15_final', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x133f3c438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=200, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './model/shuffle_5000_bs32_hdo15_final', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x133f3c438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=200, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=options['use_tpu'],\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    params={\"model_dir\": options['model_dir']},\n",
    "    train_batch_size=options['train_batch_size'],\n",
    "    eval_batch_size=options['eval_batch_size'],\n",
    "    predict_batch_size=options['eval_batch_size'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3jBMSIUzfOX"
   },
   "source": [
    "## Ready to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2188,
     "status": "ok",
     "timestamp": 1572720676594,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "t9s_kSvvzfOX",
    "outputId": "0f886424-c2b3-4403-93d4-86c8f01bbbd6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Getting data for supervised training from: ./Data/proc_data/GoT/train_5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loading training data from these files: ./Data/proc_data/GoT/train_5000/tf_examples.tfrecord.0.1 ./Data/proc_data/GoT/train_5000/tf_examples.tfrecord.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loading training data from these files: ./Data/proc_data/GoT/train_5000/tf_examples.tfrecord.0.1 ./Data/proc_data/GoT/train_5000/tf_examples.tfrecord.0.0\n"
     ]
    }
   ],
   "source": [
    "# Logical check to determine if we are training (vice evaluating)\n",
    "if options['do_train']:\n",
    "    logging.info(\"Getting data for supervised training from: {}\".format(options['sup_train_data_dir']))\n",
    "    \n",
    "    # Are we doing UDA or just simple finetuning?\n",
    "    if options['unsup_ratio'] > 0:\n",
    "        logging.info(\"Getting unsupervised data from: {}\".format(\n",
    "          options['unsup_data_dir']))\n",
    "    \n",
    "    # Pass on all of the training sup/unsup options\n",
    "    train_input_fn = proc_data_utils.training_input_fn_builder(\n",
    "        options['sup_train_data_dir'],\n",
    "        max_seq_len=options['max_seq_length'],\n",
    "        unsup_data_base_path=options['unsup_data_dir'],\n",
    "        aug_ops=options['aug_ops'],\n",
    "        aug_copy=options['aug_copy'],\n",
    "        unsup_ratio=options['unsup_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2518,
     "status": "ok",
     "timestamp": 1572720677879,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "0F6SqoYhzfOZ",
    "outputId": "cfc4058c-6e42-41f9-821e-52eb0d8e9e5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:  >>> dev data dir : ./Data/proc_data/GoT/dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loading eval clas data from these files: ./Data/proc_data/GoT/dev/tf_examples.tfrecord.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loading eval clas data from these files: ./Data/proc_data/GoT/dev/tf_examples.tfrecord.0.0\n",
      "INFO:absl:Evaluating 2500 examples in 312 steps\n"
     ]
    }
   ],
   "source": [
    "# Logical check to see if we are evaluating against the development set (or test set if you change the eval_data_dir)\n",
    "if options['do_eval']:\n",
    "    logging.info(\"  >>> dev data dir : {}\".format(options['eval_data_dir']))\n",
    "    eval_input_fn = proc_data_utils.evaluation_input_fn_builder(\n",
    "        options['eval_data_dir'],\n",
    "        \"clas\",\n",
    "        max_seq_len=options['max_seq_length'])\n",
    "\n",
    "    eval_size = processor.get_dev_size()\n",
    "    eval_steps = int(eval_size / options['eval_batch_size'])\n",
    "    logging.info(\"Evaluating {} examples in {} steps\".format(eval_size,eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3597907,
     "status": "ok",
     "timestamp": 1572724274822,
     "user": {
      "displayName": "Thomas Goter",
      "photoUrl": "",
      "userId": "00883949598941594885"
     },
     "user_tz": 240
    },
    "id": "18AJnLMvzfOb",
    "outputId": "b66e7b24-6962-4cb0-fb4b-63b177518ce9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:***** Running training & evaluation *****\n",
      "INFO:absl:  Supervised batch size = 32\n",
      "INFO:absl:  Unsupervised batch size = 0\n",
      "INFO:absl:  Num steps = 3000\n",
      "INFO:absl:  Base evaluation batch size = 8\n",
      "INFO:absl:  Num steps = 312\n",
      "INFO:absl:*** Running training: Current Step: 0***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Supervised batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Supervised batch size: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Getting training examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Getting training examples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/utils/proc_data_utils.py:142: The name tf.logging.debug is deprecated. Please use tf.compat.v1.logging.debug instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/utils/proc_data_utils.py:142: The name tf.logging.debug is deprecated. Please use tf.compat.v1.logging.debug instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Got a batch of training data of size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Got a batch of training data of size: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:total sample in a batch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:total sample in a batch: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running train on CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running train on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/uda.py:254: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/uda.py:254: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "INFO:absl:Creating supervised model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for IteratorGetNext:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for IteratorGetNext:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/modeling.py:140: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/modeling.py:140: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/modeling.py:140: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/modeling.py:140: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating bert embeddings in the embedding_lookup function of bert/modeling.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating bert embeddings in the embedding_lookup function of bert/modeling.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/modeling.py:410: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/modeling.py:410: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Post-processing the word embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Post-processing the word embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert/embeddings/Reshape:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert/embeddings/Reshape:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Adding token type embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Adding token type embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Adding positional embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Adding positional embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for IteratorGetNext:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for IteratorGetNext:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for IteratorGetNext:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for IteratorGetNext:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert/embeddings/dropout/mul_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert/embeddings/dropout/mul_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/Reshape_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/Reshape_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/Reshape_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/Reshape_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/modeling.py:681: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/modeling.py:681: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_0/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_1/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_2/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_3/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_4/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_5/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_6/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_7/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_8/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_9/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:asserting rank for bert_1/encoder/layer_10/output/LayerNorm/batchnorm/add_1:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/optimization.py:144: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/bert/optimization.py:144: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./model/shuffle_5000_bs32_hdo15_final/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./model/shuffle_5000_bs32_hdo15_final/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training_loop marked as finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training_loop marked as finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9ee516e7b4c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         estimator.train(\n\u001b[1;32m     21\u001b[0m               \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m               steps=save_checkpoints_steps)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*** Running evaluation ***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m   2869\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2870\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2871\u001b[0;31m           saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m   2872\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2873\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_loop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1190\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1191\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1482\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m             run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1253\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         logging.info(\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1336\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MIDS_TPG/W266/nlp_finalproject/tf114/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# IF we are training and evaluating\n",
    "if options['do_train'] and options['do_eval']:\n",
    "    logging.info(\"***** Running training & evaluation *****\")\n",
    "    logging.info(\"  Supervised batch size = {:d}\".format(\n",
    "        options['train_batch_size']))\n",
    "    logging.info(\"  Unsupervised batch size = {:d}\".format(\n",
    "        options['train_batch_size'] * options['unsup_ratio']))\n",
    "    logging.info(\"  Num steps = {}\".format(options['num_train_steps']))\n",
    "    logging.info(\"  Base evaluation batch size = {:d}\".format(\n",
    "        options['eval_batch_size']))\n",
    "    logging.info(\"  Num steps = {:d}\".format(eval_steps))\n",
    "    \n",
    "    # Initialize\n",
    "    best_acc = 0\n",
    "    \n",
    "    # Looping over training steps by subset (for each checkpoint)\n",
    "    for s in range(0, options['num_train_steps'], save_checkpoints_steps):\n",
    "        logging.info(\"*** Running training: Current Step: {}***\".format(s))\n",
    "        \n",
    "        estimator.train(\n",
    "              input_fn=train_input_fn,\n",
    "              steps=save_checkpoints_steps)\n",
    "        \n",
    "        logging.info(\"*** Running evaluation ***\")\n",
    "        dev_result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
    "        logging.info(\">> Results:\")\n",
    "        \n",
    "        # Keep track of the evaluation results\n",
    "        for key in dev_result.keys():\n",
    "            logging.info(\"  {} = {}\".format(key, str(dev_result[key])))\n",
    "            dev_result[key] = dev_result[key].item()\n",
    "        \n",
    "        # Update the best accuracy object\n",
    "        best_acc = max(best_acc, dev_result[\"eval_classify_accuracy\"])\n",
    "    logging.info(\"***** Final evaluation result *****\")\n",
    "    logging.info(\"Best acc: {:.3f}\\n\\n\".format(best_acc))\n",
    "elif options['do_train']:\n",
    "    logging.info(\"***** Running training *****\")\n",
    "    logging.info(\"  Supervised batch size = {}\".format(options['train_batch_size']))\n",
    "    logging.info(\"  Unsupervised batch size = {}\".format(\n",
    "                    options['train_batch_size'] * options['unsup_ratio']))\n",
    "    logging.info(\"  Num steps = {}\".format(options['num_train_steps']))\n",
    "    estimator.train(input_fn=train_input_fn, max_steps=options['num_train_steps'])\n",
    "elif options['do_eval']:\n",
    "    logging.info(\"***** Running evaluation *****\")\n",
    "    logging.info(\"  Base evaluation batch size = {}\".format(options['eval_batch_size']))\n",
    "    logging.info(\"  Num steps = {}\".format(eval_steps))\n",
    "    \n",
    "    # Load in the checkpoint from training to do the evaluation\n",
    "    checkpoint_state = tf.train.get_checkpoint_state(options['model_dir'])\n",
    "\n",
    "    best_acc = 0\n",
    "    for ckpt_path in checkpoint_state.all_model_checkpoint_paths:\n",
    "        if not tf.io.gfile.exists(ckpt_path + \".data-00000-of-00001\"):\n",
    "            logging.info(\n",
    "                \"Warning: checkpoint {:s} does not exist\".format(ckpt_path))\n",
    "        continue\n",
    "        logging.info(\"Evaluating {:s}\".format(ckpt_path))\n",
    "        dev_result = estimator.evaluate(\n",
    "          input_fn=eval_input_fn,\n",
    "          steps=eval_steps,\n",
    "          checkpoint_path=ckpt_path,)\n",
    "        logging.info(\">> Results:\")\n",
    "        \n",
    "        # keep track of evaluation metrics\n",
    "        for key in dev_result.keys():\n",
    "            logging.info(\"  {:s} = {:s}\".format(key, str(dev_result[key])))\n",
    "            dev_result[key] = dev_result[key].item()\n",
    "        \n",
    "        # update our best accuracy variable\n",
    "        best_acc = max(best_acc, dev_result[\"eval_classify_accuracy\"])\n",
    "    logging.info(\"***** Final evaluation result *****\")\n",
    "    logging.info(\"Best acc: {:.3f}\\n\\n\".format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ydw7BcLqPbJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_ft_5000_colab.ipynb",
   "provenance": [
    {
     "file_id": "1D2lB33iOt6c1MZmnNvQztxOcwuuHPdGd",
     "timestamp": 1572199883490
    },
    {
     "file_id": "18jrsxVnwUI8y5T4Ild8vIYoo9rRFGg0a",
     "timestamp": 1572116425406
    }
   ]
  },
  "kernelspec": {
   "display_name": "tf114",
   "language": "python",
   "name": "tf114"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
